{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 551\n",
      "Trainable params: 551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from pprint import pprint\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "# Multilayer Perceptron\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "visible = Input(shape=(10,))\n",
    "hidden1 = Dense(10, activation='relu')(visible)\n",
    "hidden2 = Dense(20, activation='relu')(hidden1)\n",
    "hidden3 = Dense(10, activation='relu')(hidden2)\n",
    "output = Dense(1, activation='sigmoid')(hidden3)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "print(model.summary())\n",
    "# plot graph\n",
    "plot_model(model, to_file='multilayer_perceptron_graph.png')\n",
    "\n",
    "# Multilayer Perceptron\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1421f7250>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "studentStatus = df.label.value_counts(normalize=True)\n",
    "studentStatus.plot(kind=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'ssc p', 'ssc b', 'hsc p', 'hsc b', 'hsc s', 'degree p', 'degree t', 'workex', 'etest p', 'specialisation', 'mba p', 'label']\n",
      "     gender     ssc p  ssc b     hsc p  hsc b  hsc s  degree p  degree t  \\\n",
      "0         1  0.067034      1  0.092328      1      1  0.059237         2   \n",
      "1         1  0.079370      0  0.079473      1      2  0.079133         2   \n",
      "2         1  0.065033      0  0.068993      0      0  0.065365         0   \n",
      "3         1  0.056029      0  0.052759      0      2  0.053109         2   \n",
      "4         1  0.085844      0  0.074674      0      1  0.074864         0   \n",
      "..      ...       ...    ...       ...    ...    ...       ...       ...   \n",
      "210       1  0.080641      1  0.083197      1      1  0.079255         0   \n",
      "211       1  0.058030      1  0.060876      1      2  0.073536         2   \n",
      "212       1  0.067034      1  0.067978      1      1  0.074557         0   \n",
      "213       0  0.074038      1  0.066963      1      1  0.059237         0   \n",
      "214       1  0.062032      0  0.058847      1      2  0.054131         0   \n",
      "\n",
      "     workex   etest p  specialisation     mba p  label  \n",
      "0         0  0.051168               1  0.064111      1  \n",
      "1         1  0.080473               0  0.072267      1  \n",
      "2         0  0.069774               0  0.063021      1  \n",
      "3         0  0.061402               1  0.064798      0  \n",
      "4         0  0.090056               0  0.060513      1  \n",
      "..      ...       ...             ...       ...    ...  \n",
      "210       0  0.084660               0  0.081218      1  \n",
      "211       0  0.068844               0  0.058463      1  \n",
      "212       1  0.054889               0  0.076018      1  \n",
      "213       0  0.065123               1  0.065670      1  \n",
      "214       0  0.082799               1  0.065659      0  \n",
      "\n",
      "[215 rows x 13 columns]\n",
      "training data (215, 12) data label (215,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Placement_Data_Full_Class.csv\")\n",
    "df = df.drop(\"salary\", axis=1)\n",
    "df[\"label\"] = df.status\n",
    "df = df.drop(\"status\", axis=1)\n",
    "df = df.drop(\"sl_no\", axis=1)\n",
    "column_names = []\n",
    "for column in df:\n",
    "    name = column.replace(\"_\", \" \")\n",
    "    column_names.append(name)\n",
    "df.columns = column_names\n",
    "\n",
    "le = LabelEncoder()\n",
    "category = [column for column in df]\n",
    "print([column for column in df])\n",
    "for col in [column for column in df]:\n",
    "    #data = array(df[col])\n",
    "    if(col==\"ssc p\" or col==\"hsc p\" or col ==\"degree p\" or col == \"etest p\" or col==\"mba p\"):\n",
    "        norm_data = tf.keras.utils.normalize(array(df[col]), axis=-1, order=2)\n",
    "        temp = pd.DataFrame({col: norm_data[0]})\n",
    "        df[col] = temp[col]\n",
    "     \n",
    "        \n",
    "#male=1,female=0\n",
    "df[\"gender\"] = le.fit_transform(df[\"gender\"])\n",
    "#1 other,0 central\n",
    "df[\"ssc b\"] = le.fit_transform(df[\"ssc b\"])\n",
    "#1 other,0 central\n",
    "df[\"hsc b\"] = le.fit_transform(df[\"hsc b\"])\n",
    "#commerce 1, science 2, art 0\n",
    "df[\"hsc s\"] = le.fit_transform(df[\"hsc s\"])\n",
    "#Sci&Tech 2,Comm&Mgmt 0,Others 1\n",
    "df[\"degree t\"] = le.fit_transform(df[\"degree t\"])\n",
    "#yes 1, no 0\n",
    "df[\"workex\"] = le.fit_transform(df[\"workex\"])\n",
    "#Mkt&HR 1,Mkt&Fin 0\n",
    "df[\"specialisation\"] = le.fit_transform(df[\"specialisation\"])\n",
    "df['label']=le.fit_transform(df[\"label\"])\n",
    "print(df)\n",
    "\n",
    "df.head()\n",
    "# shuffle the dataset\n",
    "np.random.shuffle(np.array(df))\n",
    "\n",
    "#Select important features\n",
    "#df = SelectKBest(chi2, k=20).fit_transform(X, y)\n",
    "# get the label\n",
    "label = df.label\n",
    "label = np.array(label)\n",
    "# get the training data\n",
    "data = df.drop(\"label\",axis=1)\n",
    "data = np.array(data)\n",
    "\n",
    "#newdata = SelectKBest(chi2, k=2).fit_transform(data, label)\n",
    "#print(\"newdata\",newdata)\n",
    "\n",
    "print(\"training data\",data.shape, \"data label\",label.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain [[1.         0.06203157 0.         ... 0.06233183 0.         0.06159257]\n",
      " [0.         0.06403259 1.         ... 0.04651629 0.         0.06814544]\n",
      " [1.         0.05202648 1.         ... 0.05581955 0.         0.06380594]\n",
      " ...\n",
      " [1.         0.0770392  1.         ... 0.07442607 0.         0.07310643]\n",
      " [1.         0.06303208 0.         ... 0.07256542 0.         0.05947734]\n",
      " [1.         0.07303717 1.         ... 0.07814737 1.         0.05739482]] (193, 12)\n",
      "xtest [[0.         0.06703411 0.         0.0710218  0.         1.\n",
      "  0.06638657 1.         0.         0.08186868 1.         0.07845993]\n",
      " [0.         0.07904022 0.         0.07710938 0.         2.\n",
      "  0.06699937 2.         0.         0.0539589  1.         0.06048044]\n",
      " [0.         0.08404277 1.         0.07609478 1.         2.\n",
      "  0.0704719  2.         1.         0.0576802  1.         0.06799279]\n",
      " [0.         0.04802444 0.         0.05174445 0.         1.\n",
      "  0.05923725 0.         1.         0.05581955 1.         0.06410033]\n",
      " [1.         0.08004073 1.         0.08116777 1.         1.\n",
      "  0.07353589 0.         1.         0.05934549 0.         0.0720052 ]\n",
      " [0.         0.05903004 0.         0.06290502 1.         1.\n",
      "  0.07915322 0.         0.         0.06884412 1.         0.07305191]\n",
      " [0.         0.0760387  0.         0.0710218  0.         2.\n",
      "  0.07762122 0.         1.         0.06140151 0.         0.07026067]\n",
      " [1.         0.06703411 1.         0.06391962 0.         1.\n",
      "  0.07353589 0.         0.         0.05209825 1.         0.06586666]\n",
      " [1.         0.055028   1.         0.05052694 1.         2.\n",
      "  0.06868456 2.         1.         0.05116792 0.         0.05623907]\n",
      " [1.         0.08404277 1.         0.08015317 1.         2.\n",
      "  0.06945056 2.         1.         0.07814737 0.         0.07271391]\n",
      " [1.         0.06043075 0.         0.06757217 1.         2.\n",
      "  0.06638657 0.         0.         0.06605314 1.         0.05747114]\n",
      " [1.         0.08944552 1.         0.06661845 1.         2.\n",
      "  0.07276989 2.         0.         0.06698346 1.         0.06894138]\n",
      " [1.         0.0870443  0.         0.07508019 0.         2.\n",
      "  0.06638657 2.         1.         0.06977444 1.         0.07881974]\n",
      " [1.         0.05802953 1.         0.06189043 1.         1.\n",
      "  0.06230124 0.         0.         0.0539589  1.         0.05881224]\n",
      " [1.         0.05662882 0.         0.06574589 0.         1.\n",
      "  0.07169749 0.         0.         0.07839856 0.         0.07326998]\n",
      " [1.         0.05570835 1.         0.06222524 1.         1.\n",
      "  0.05808314 0.         0.         0.06140151 1.         0.06356607]\n",
      " [0.         0.07904022 1.         0.06189043 1.         2.\n",
      "  0.07711055 2.         1.         0.06512281 0.         0.0743603 ]\n",
      " [0.         0.04702393 0.         0.05580284 1.         2.\n",
      "  0.06638657 0.         0.         0.0576802  1.         0.07091487]\n",
      " [1.         0.04902495 1.         0.05986123 1.         2.\n",
      "  0.06638657 2.         1.         0.08000803 0.         0.06812363]\n",
      " [1.         0.06703411 1.         0.06391962 1.         2.\n",
      "  0.06536524 2.         0.         0.05581955 0.         0.06745853]\n",
      " [1.         0.05999053 1.         0.04277542 1.         2.\n",
      "  0.06256679 2.         0.         0.05068415 1.         0.07139461]\n",
      " [1.         0.0660336  0.         0.06493422 0.         2.\n",
      "  0.06127991 0.         0.         0.05581955 1.         0.06749124]]\n",
      "yTrain [1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
      " 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0\n",
      " 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 0 1 1 1 1 1 1 0 1 1\n",
      " 1 1 0 1 1 0 1 0 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 0 1 1 1 1 1 1 1]\n",
      "yTest [0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(data, label, test_size = 0.1, random_state = 0)\n",
    "print(\"xtrain\",xTrain, xTrain.shape)\n",
    "print(\"xtest\",xTest)\n",
    "print(\"yTrain\",yTrain)\n",
    "print(\"yTest\",yTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(xTrain,yTrain)\n",
    "y_pred = tree.predict(xTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(yTest, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest \n",
    "randomForest=RandomForestClassifier(n_estimators=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=64)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomForest.fit(xTrain,yTrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred [1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1]\n",
      "yTest [0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred=randomForest.predict(xTest)\n",
    "print(\"y_pred\",y_pred)\n",
    "print(\"yTest\",yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest Accuracy: 0.6818181818181818\n"
     ]
    }
   ],
   "source": [
    "print(\"Random forest Accuracy:\",metrics.accuracy_score(yTest, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple perceptron \n",
    "model = Sequential()\n",
    "model.add(Dense(9,  activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Layer dense_134 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.2922 - accuracy: 0.3237 - val_loss: 0.3123 - val_accuracy: 0.1500\n",
      "Epoch 2/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2855 - accuracy: 0.3179 - val_loss: 0.3017 - val_accuracy: 0.2500\n",
      "Epoch 3/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2791 - accuracy: 0.3699 - val_loss: 0.2919 - val_accuracy: 0.2500\n",
      "Epoch 4/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2738 - accuracy: 0.3757 - val_loss: 0.2828 - val_accuracy: 0.3000\n",
      "Epoch 5/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2685 - accuracy: 0.3757 - val_loss: 0.2748 - val_accuracy: 0.2500\n",
      "Epoch 6/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2638 - accuracy: 0.4220 - val_loss: 0.2674 - val_accuracy: 0.2000\n",
      "Epoch 7/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2594 - accuracy: 0.4104 - val_loss: 0.2597 - val_accuracy: 0.2500\n",
      "Epoch 8/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2546 - accuracy: 0.4277 - val_loss: 0.2518 - val_accuracy: 0.3500\n",
      "Epoch 9/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2499 - accuracy: 0.4624 - val_loss: 0.2442 - val_accuracy: 0.6000\n",
      "Epoch 10/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2452 - accuracy: 0.5491 - val_loss: 0.2368 - val_accuracy: 0.6500\n",
      "Epoch 11/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2403 - accuracy: 0.5896 - val_loss: 0.2306 - val_accuracy: 0.6500\n",
      "Epoch 12/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2365 - accuracy: 0.6127 - val_loss: 0.2233 - val_accuracy: 0.7500\n",
      "Epoch 13/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2318 - accuracy: 0.6358 - val_loss: 0.2156 - val_accuracy: 0.7500\n",
      "Epoch 14/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2284 - accuracy: 0.6647 - val_loss: 0.2084 - val_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2251 - accuracy: 0.6821 - val_loss: 0.2019 - val_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2222 - accuracy: 0.6879 - val_loss: 0.1964 - val_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2195 - accuracy: 0.6821 - val_loss: 0.1909 - val_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2171 - accuracy: 0.6821 - val_loss: 0.1857 - val_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2152 - accuracy: 0.6821 - val_loss: 0.1807 - val_accuracy: 0.8500\n",
      "Epoch 20/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2133 - accuracy: 0.6821 - val_loss: 0.1755 - val_accuracy: 0.8500\n",
      "Epoch 21/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2115 - accuracy: 0.6821 - val_loss: 0.1710 - val_accuracy: 0.8500\n",
      "Epoch 22/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2093 - accuracy: 0.6821 - val_loss: 0.1677 - val_accuracy: 0.8500\n",
      "Epoch 23/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2077 - accuracy: 0.6821 - val_loss: 0.1646 - val_accuracy: 0.8500\n",
      "Epoch 24/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2065 - accuracy: 0.6821 - val_loss: 0.1611 - val_accuracy: 0.8500\n",
      "Epoch 25/1000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2054 - accuracy: 0.6821 - val_loss: 0.1584 - val_accuracy: 0.8500\n",
      "Epoch 26/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2045 - accuracy: 0.6821 - val_loss: 0.1565 - val_accuracy: 0.8500\n",
      "Epoch 27/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2035 - accuracy: 0.6821 - val_loss: 0.1554 - val_accuracy: 0.8500\n",
      "Epoch 28/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2029 - accuracy: 0.6821 - val_loss: 0.1536 - val_accuracy: 0.8500\n",
      "Epoch 29/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.2022 - accuracy: 0.6821 - val_loss: 0.1527 - val_accuracy: 0.8500\n",
      "Epoch 30/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2015 - accuracy: 0.6821 - val_loss: 0.1521 - val_accuracy: 0.8500\n",
      "Epoch 31/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2010 - accuracy: 0.6821 - val_loss: 0.1517 - val_accuracy: 0.8500\n",
      "Epoch 32/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.2004 - accuracy: 0.6821 - val_loss: 0.1516 - val_accuracy: 0.8500\n",
      "Epoch 33/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1998 - accuracy: 0.6821 - val_loss: 0.1507 - val_accuracy: 0.8500\n",
      "Epoch 34/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1994 - accuracy: 0.6821 - val_loss: 0.1502 - val_accuracy: 0.8500\n",
      "Epoch 35/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1989 - accuracy: 0.6821 - val_loss: 0.1499 - val_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1985 - accuracy: 0.6821 - val_loss: 0.1494 - val_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1980 - accuracy: 0.6821 - val_loss: 0.1499 - val_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1976 - accuracy: 0.6821 - val_loss: 0.1501 - val_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.6821 - val_loss: 0.1503 - val_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1968 - accuracy: 0.6821 - val_loss: 0.1504 - val_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1963 - accuracy: 0.6821 - val_loss: 0.1499 - val_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1960 - accuracy: 0.6821 - val_loss: 0.1493 - val_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1957 - accuracy: 0.6821 - val_loss: 0.1495 - val_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1953 - accuracy: 0.6821 - val_loss: 0.1497 - val_accuracy: 0.8000\n",
      "Epoch 45/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1949 - accuracy: 0.6821 - val_loss: 0.1490 - val_accuracy: 0.8000\n",
      "Epoch 46/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1946 - accuracy: 0.6821 - val_loss: 0.1488 - val_accuracy: 0.8000\n",
      "Epoch 47/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1943 - accuracy: 0.6821 - val_loss: 0.1487 - val_accuracy: 0.8000\n",
      "Epoch 48/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1939 - accuracy: 0.6821 - val_loss: 0.1497 - val_accuracy: 0.8000\n",
      "Epoch 49/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1936 - accuracy: 0.6879 - val_loss: 0.1500 - val_accuracy: 0.8000\n",
      "Epoch 50/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1932 - accuracy: 0.6879 - val_loss: 0.1502 - val_accuracy: 0.8000\n",
      "Epoch 51/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1929 - accuracy: 0.6879 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 52/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1927 - accuracy: 0.6879 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 53/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1923 - accuracy: 0.6879 - val_loss: 0.1515 - val_accuracy: 0.8000\n",
      "Epoch 54/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1920 - accuracy: 0.6879 - val_loss: 0.1521 - val_accuracy: 0.8000\n",
      "Epoch 55/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1919 - accuracy: 0.6879 - val_loss: 0.1524 - val_accuracy: 0.8000\n",
      "Epoch 56/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1915 - accuracy: 0.6879 - val_loss: 0.1524 - val_accuracy: 0.8000\n",
      "Epoch 57/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.6879 - val_loss: 0.1521 - val_accuracy: 0.8000\n",
      "Epoch 58/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1910 - accuracy: 0.6879 - val_loss: 0.1512 - val_accuracy: 0.8000\n",
      "Epoch 59/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1908 - accuracy: 0.6879 - val_loss: 0.1508 - val_accuracy: 0.8000\n",
      "Epoch 60/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1905 - accuracy: 0.6879 - val_loss: 0.1512 - val_accuracy: 0.8000\n",
      "Epoch 61/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.6879 - val_loss: 0.1518 - val_accuracy: 0.8000\n",
      "Epoch 62/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1901 - accuracy: 0.6879 - val_loss: 0.1524 - val_accuracy: 0.8000\n",
      "Epoch 63/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1898 - accuracy: 0.6879 - val_loss: 0.1520 - val_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1897 - accuracy: 0.6879 - val_loss: 0.1514 - val_accuracy: 0.8000\n",
      "Epoch 65/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.6879 - val_loss: 0.1521 - val_accuracy: 0.8000\n",
      "Epoch 66/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1892 - accuracy: 0.6879 - val_loss: 0.1520 - val_accuracy: 0.8000\n",
      "Epoch 67/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1889 - accuracy: 0.6879 - val_loss: 0.1514 - val_accuracy: 0.8000\n",
      "Epoch 68/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1887 - accuracy: 0.6879 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 69/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1886 - accuracy: 0.6879 - val_loss: 0.1505 - val_accuracy: 0.8000\n",
      "Epoch 70/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1884 - accuracy: 0.6879 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 71/1000\n",
      "6/6 [==============================] - 1s 114ms/step - loss: 0.1882 - accuracy: 0.6879 - val_loss: 0.1503 - val_accuracy: 0.8000\n",
      "Epoch 72/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1882 - accuracy: 0.6879 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 73/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1879 - accuracy: 0.6879 - val_loss: 0.1509 - val_accuracy: 0.8000\n",
      "Epoch 74/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1878 - accuracy: 0.6879 - val_loss: 0.1501 - val_accuracy: 0.8000\n",
      "Epoch 75/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1876 - accuracy: 0.6879 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 76/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1874 - accuracy: 0.6879 - val_loss: 0.1505 - val_accuracy: 0.8000\n",
      "Epoch 77/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1871 - accuracy: 0.6879 - val_loss: 0.1511 - val_accuracy: 0.8000\n",
      "Epoch 78/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1869 - accuracy: 0.6879 - val_loss: 0.1508 - val_accuracy: 0.8000\n",
      "Epoch 79/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1867 - accuracy: 0.6879 - val_loss: 0.1498 - val_accuracy: 0.8000\n",
      "Epoch 80/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1866 - accuracy: 0.6879 - val_loss: 0.1497 - val_accuracy: 0.8000\n",
      "Epoch 81/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1864 - accuracy: 0.6879 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 82/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1863 - accuracy: 0.6936 - val_loss: 0.1513 - val_accuracy: 0.8000\n",
      "Epoch 83/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1862 - accuracy: 0.6994 - val_loss: 0.1503 - val_accuracy: 0.8000\n",
      "Epoch 84/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1860 - accuracy: 0.6994 - val_loss: 0.1512 - val_accuracy: 0.8000\n",
      "Epoch 85/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1858 - accuracy: 0.6994 - val_loss: 0.1513 - val_accuracy: 0.8000\n",
      "Epoch 86/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1855 - accuracy: 0.6994 - val_loss: 0.1508 - val_accuracy: 0.8000\n",
      "Epoch 87/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1854 - accuracy: 0.6936 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 88/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1853 - accuracy: 0.6936 - val_loss: 0.1511 - val_accuracy: 0.8000\n",
      "Epoch 89/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1851 - accuracy: 0.6936 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 90/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1850 - accuracy: 0.6936 - val_loss: 0.1514 - val_accuracy: 0.8000\n",
      "Epoch 91/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1849 - accuracy: 0.6936 - val_loss: 0.1514 - val_accuracy: 0.8000\n",
      "Epoch 92/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1847 - accuracy: 0.6936 - val_loss: 0.1513 - val_accuracy: 0.8000\n",
      "Epoch 93/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1846 - accuracy: 0.6936 - val_loss: 0.1511 - val_accuracy: 0.8000\n",
      "Epoch 94/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1844 - accuracy: 0.6936 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 95/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1843 - accuracy: 0.6936 - val_loss: 0.1513 - val_accuracy: 0.8000\n",
      "Epoch 96/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1843 - accuracy: 0.6936 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 97/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1841 - accuracy: 0.6936 - val_loss: 0.1508 - val_accuracy: 0.8000\n",
      "Epoch 98/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1839 - accuracy: 0.6936 - val_loss: 0.1511 - val_accuracy: 0.8000\n",
      "Epoch 99/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1838 - accuracy: 0.6936 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 100/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1837 - accuracy: 0.6936 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 101/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1835 - accuracy: 0.6936 - val_loss: 0.1514 - val_accuracy: 0.8000\n",
      "Epoch 102/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1834 - accuracy: 0.6936 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 103/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1833 - accuracy: 0.6936 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 104/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1831 - accuracy: 0.6936 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 105/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1830 - accuracy: 0.6936 - val_loss: 0.1512 - val_accuracy: 0.8000\n",
      "Epoch 106/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1829 - accuracy: 0.6936 - val_loss: 0.1515 - val_accuracy: 0.8000\n",
      "Epoch 107/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1828 - accuracy: 0.6936 - val_loss: 0.1522 - val_accuracy: 0.8000\n",
      "Epoch 108/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1827 - accuracy: 0.7052 - val_loss: 0.1518 - val_accuracy: 0.8000\n",
      "Epoch 109/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1825 - accuracy: 0.6994 - val_loss: 0.1515 - val_accuracy: 0.8000\n",
      "Epoch 110/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.6994 - val_loss: 0.1517 - val_accuracy: 0.8000\n",
      "Epoch 111/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1826 - accuracy: 0.6936 - val_loss: 0.1507 - val_accuracy: 0.8000\n",
      "Epoch 112/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.6936 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 113/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1823 - accuracy: 0.6936 - val_loss: 0.1533 - val_accuracy: 0.8000\n",
      "Epoch 114/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1820 - accuracy: 0.6994 - val_loss: 0.1537 - val_accuracy: 0.8000\n",
      "Epoch 115/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1820 - accuracy: 0.6994 - val_loss: 0.1534 - val_accuracy: 0.8000\n",
      "Epoch 116/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1818 - accuracy: 0.6936 - val_loss: 0.1533 - val_accuracy: 0.8000\n",
      "Epoch 117/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1817 - accuracy: 0.6936 - val_loss: 0.1534 - val_accuracy: 0.8000\n",
      "Epoch 118/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1815 - accuracy: 0.6936 - val_loss: 0.1531 - val_accuracy: 0.8000\n",
      "Epoch 119/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1815 - accuracy: 0.6879 - val_loss: 0.1526 - val_accuracy: 0.8000\n",
      "Epoch 120/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1814 - accuracy: 0.6879 - val_loss: 0.1533 - val_accuracy: 0.8000\n",
      "Epoch 121/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1812 - accuracy: 0.6879 - val_loss: 0.1535 - val_accuracy: 0.8000\n",
      "Epoch 122/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1812 - accuracy: 0.6879 - val_loss: 0.1538 - val_accuracy: 0.8000\n",
      "Epoch 123/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1810 - accuracy: 0.6879 - val_loss: 0.1539 - val_accuracy: 0.8000\n",
      "Epoch 124/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1809 - accuracy: 0.6879 - val_loss: 0.1535 - val_accuracy: 0.8000\n",
      "Epoch 125/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1808 - accuracy: 0.6879 - val_loss: 0.1529 - val_accuracy: 0.8000\n",
      "Epoch 126/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1807 - accuracy: 0.6879 - val_loss: 0.1535 - val_accuracy: 0.8000\n",
      "Epoch 127/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1806 - accuracy: 0.6879 - val_loss: 0.1543 - val_accuracy: 0.8000\n",
      "Epoch 128/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1805 - accuracy: 0.6936 - val_loss: 0.1547 - val_accuracy: 0.8000\n",
      "Epoch 129/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1804 - accuracy: 0.6936 - val_loss: 0.1546 - val_accuracy: 0.8000\n",
      "Epoch 130/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1803 - accuracy: 0.6879 - val_loss: 0.1546 - val_accuracy: 0.8000\n",
      "Epoch 131/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1802 - accuracy: 0.6879 - val_loss: 0.1546 - val_accuracy: 0.8000\n",
      "Epoch 132/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1800 - accuracy: 0.6936 - val_loss: 0.1555 - val_accuracy: 0.8000\n",
      "Epoch 133/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1800 - accuracy: 0.6936 - val_loss: 0.1559 - val_accuracy: 0.8000\n",
      "Epoch 134/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1799 - accuracy: 0.6936 - val_loss: 0.1553 - val_accuracy: 0.7500\n",
      "Epoch 135/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1798 - accuracy: 0.7225 - val_loss: 0.1555 - val_accuracy: 0.7500\n",
      "Epoch 136/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1796 - accuracy: 0.7225 - val_loss: 0.1555 - val_accuracy: 0.7500\n",
      "Epoch 137/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1795 - accuracy: 0.7283 - val_loss: 0.1555 - val_accuracy: 0.7500\n",
      "Epoch 138/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1794 - accuracy: 0.7225 - val_loss: 0.1551 - val_accuracy: 0.7500\n",
      "Epoch 139/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1793 - accuracy: 0.7225 - val_loss: 0.1554 - val_accuracy: 0.7500\n",
      "Epoch 140/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1792 - accuracy: 0.7168 - val_loss: 0.1559 - val_accuracy: 0.7500\n",
      "Epoch 141/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1791 - accuracy: 0.7168 - val_loss: 0.1551 - val_accuracy: 0.7500\n",
      "Epoch 142/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1790 - accuracy: 0.7225 - val_loss: 0.1550 - val_accuracy: 0.7500\n",
      "Epoch 143/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1789 - accuracy: 0.7110 - val_loss: 0.1561 - val_accuracy: 0.7000\n",
      "Epoch 144/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1789 - accuracy: 0.7225 - val_loss: 0.1566 - val_accuracy: 0.7000\n",
      "Epoch 145/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1786 - accuracy: 0.7225 - val_loss: 0.1563 - val_accuracy: 0.7500\n",
      "Epoch 146/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1786 - accuracy: 0.7110 - val_loss: 0.1562 - val_accuracy: 0.7500\n",
      "Epoch 147/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1786 - accuracy: 0.7052 - val_loss: 0.1557 - val_accuracy: 0.7500\n",
      "Epoch 148/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1785 - accuracy: 0.7110 - val_loss: 0.1574 - val_accuracy: 0.7000\n",
      "Epoch 149/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1782 - accuracy: 0.7225 - val_loss: 0.1578 - val_accuracy: 0.7000\n",
      "Epoch 150/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1783 - accuracy: 0.7225 - val_loss: 0.1583 - val_accuracy: 0.7000\n",
      "Epoch 151/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1780 - accuracy: 0.7225 - val_loss: 0.1582 - val_accuracy: 0.7000\n",
      "Epoch 152/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1781 - accuracy: 0.7168 - val_loss: 0.1571 - val_accuracy: 0.7500\n",
      "Epoch 153/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1778 - accuracy: 0.7225 - val_loss: 0.1576 - val_accuracy: 0.7500\n",
      "Epoch 154/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1777 - accuracy: 0.7168 - val_loss: 0.1581 - val_accuracy: 0.7000\n",
      "Epoch 155/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1775 - accuracy: 0.7283 - val_loss: 0.1591 - val_accuracy: 0.7000\n",
      "Epoch 156/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1775 - accuracy: 0.7399 - val_loss: 0.1605 - val_accuracy: 0.7000\n",
      "Epoch 157/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1775 - accuracy: 0.7341 - val_loss: 0.1607 - val_accuracy: 0.7000\n",
      "Epoch 158/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1776 - accuracy: 0.7283 - val_loss: 0.1612 - val_accuracy: 0.7000\n",
      "Epoch 159/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1775 - accuracy: 0.7283 - val_loss: 0.1610 - val_accuracy: 0.7000\n",
      "Epoch 160/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1773 - accuracy: 0.7341 - val_loss: 0.1605 - val_accuracy: 0.7000\n",
      "Epoch 161/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1771 - accuracy: 0.7341 - val_loss: 0.1598 - val_accuracy: 0.7000\n",
      "Epoch 162/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1770 - accuracy: 0.7225 - val_loss: 0.1594 - val_accuracy: 0.7000\n",
      "Epoch 163/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1768 - accuracy: 0.7225 - val_loss: 0.1593 - val_accuracy: 0.7000\n",
      "Epoch 164/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1767 - accuracy: 0.7225 - val_loss: 0.1595 - val_accuracy: 0.7000\n",
      "Epoch 165/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1767 - accuracy: 0.7168 - val_loss: 0.1598 - val_accuracy: 0.7000\n",
      "Epoch 166/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1766 - accuracy: 0.7225 - val_loss: 0.1594 - val_accuracy: 0.7000\n",
      "Epoch 167/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1766 - accuracy: 0.7283 - val_loss: 0.1606 - val_accuracy: 0.7000\n",
      "Epoch 168/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1763 - accuracy: 0.7283 - val_loss: 0.1605 - val_accuracy: 0.7000\n",
      "Epoch 169/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1762 - accuracy: 0.7283 - val_loss: 0.1605 - val_accuracy: 0.7000\n",
      "Epoch 170/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1762 - accuracy: 0.7341 - val_loss: 0.1610 - val_accuracy: 0.7000\n",
      "Epoch 171/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1760 - accuracy: 0.7399 - val_loss: 0.1613 - val_accuracy: 0.7000\n",
      "Epoch 172/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1759 - accuracy: 0.7283 - val_loss: 0.1614 - val_accuracy: 0.7000\n",
      "Epoch 173/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1758 - accuracy: 0.7283 - val_loss: 0.1614 - val_accuracy: 0.7000\n",
      "Epoch 174/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1757 - accuracy: 0.7399 - val_loss: 0.1615 - val_accuracy: 0.7000\n",
      "Epoch 175/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1756 - accuracy: 0.7399 - val_loss: 0.1617 - val_accuracy: 0.7000\n",
      "Epoch 176/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1755 - accuracy: 0.7341 - val_loss: 0.1615 - val_accuracy: 0.7000\n",
      "Epoch 177/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1755 - accuracy: 0.7341 - val_loss: 0.1617 - val_accuracy: 0.7000\n",
      "Epoch 178/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1756 - accuracy: 0.7283 - val_loss: 0.1625 - val_accuracy: 0.7000\n",
      "Epoch 179/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1755 - accuracy: 0.7283 - val_loss: 0.1621 - val_accuracy: 0.7000\n",
      "Epoch 180/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1752 - accuracy: 0.7341 - val_loss: 0.1626 - val_accuracy: 0.7000\n",
      "Epoch 181/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1751 - accuracy: 0.7341 - val_loss: 0.1629 - val_accuracy: 0.7000\n",
      "Epoch 182/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.7283 - val_loss: 0.1629 - val_accuracy: 0.7000\n",
      "Epoch 183/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1749 - accuracy: 0.7341 - val_loss: 0.1632 - val_accuracy: 0.7000\n",
      "Epoch 184/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1749 - accuracy: 0.7399 - val_loss: 0.1639 - val_accuracy: 0.7000\n",
      "Epoch 185/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1747 - accuracy: 0.7457 - val_loss: 0.1645 - val_accuracy: 0.7000\n",
      "Epoch 186/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1747 - accuracy: 0.7341 - val_loss: 0.1650 - val_accuracy: 0.7000\n",
      "Epoch 187/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1745 - accuracy: 0.7341 - val_loss: 0.1647 - val_accuracy: 0.7000\n",
      "Epoch 188/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1744 - accuracy: 0.7514 - val_loss: 0.1641 - val_accuracy: 0.7000\n",
      "Epoch 189/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1743 - accuracy: 0.7457 - val_loss: 0.1643 - val_accuracy: 0.7000\n",
      "Epoch 190/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1741 - accuracy: 0.7399 - val_loss: 0.1646 - val_accuracy: 0.7000\n",
      "Epoch 191/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1741 - accuracy: 0.7399 - val_loss: 0.1658 - val_accuracy: 0.7000\n",
      "Epoch 192/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1740 - accuracy: 0.7399 - val_loss: 0.1663 - val_accuracy: 0.7000\n",
      "Epoch 193/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.7399 - val_loss: 0.1661 - val_accuracy: 0.7000\n",
      "Epoch 194/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1738 - accuracy: 0.7399 - val_loss: 0.1662 - val_accuracy: 0.7000\n",
      "Epoch 195/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1737 - accuracy: 0.7399 - val_loss: 0.1665 - val_accuracy: 0.7000\n",
      "Epoch 196/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1737 - accuracy: 0.7341 - val_loss: 0.1668 - val_accuracy: 0.7000\n",
      "Epoch 197/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1735 - accuracy: 0.7341 - val_loss: 0.1665 - val_accuracy: 0.7000\n",
      "Epoch 198/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1735 - accuracy: 0.7399 - val_loss: 0.1668 - val_accuracy: 0.7000\n",
      "Epoch 199/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1734 - accuracy: 0.7514 - val_loss: 0.1662 - val_accuracy: 0.7000\n",
      "Epoch 200/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1732 - accuracy: 0.7457 - val_loss: 0.1671 - val_accuracy: 0.7000\n",
      "Epoch 201/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1734 - accuracy: 0.7457 - val_loss: 0.1676 - val_accuracy: 0.7000\n",
      "Epoch 202/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1731 - accuracy: 0.7457 - val_loss: 0.1677 - val_accuracy: 0.7000\n",
      "Epoch 203/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1730 - accuracy: 0.7514 - val_loss: 0.1682 - val_accuracy: 0.7000\n",
      "Epoch 204/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1729 - accuracy: 0.7572 - val_loss: 0.1682 - val_accuracy: 0.7000\n",
      "Epoch 205/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1729 - accuracy: 0.7572 - val_loss: 0.1680 - val_accuracy: 0.7000\n",
      "Epoch 206/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1727 - accuracy: 0.7630 - val_loss: 0.1682 - val_accuracy: 0.7000\n",
      "Epoch 207/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1726 - accuracy: 0.7514 - val_loss: 0.1685 - val_accuracy: 0.7000\n",
      "Epoch 208/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1725 - accuracy: 0.7514 - val_loss: 0.1688 - val_accuracy: 0.7000\n",
      "Epoch 209/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1725 - accuracy: 0.7514 - val_loss: 0.1690 - val_accuracy: 0.7000\n",
      "Epoch 210/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.7514 - val_loss: 0.1690 - val_accuracy: 0.7000\n",
      "Epoch 211/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1723 - accuracy: 0.7514 - val_loss: 0.1683 - val_accuracy: 0.7000\n",
      "Epoch 212/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1722 - accuracy: 0.7514 - val_loss: 0.1690 - val_accuracy: 0.7000\n",
      "Epoch 213/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1721 - accuracy: 0.7514 - val_loss: 0.1694 - val_accuracy: 0.7000\n",
      "Epoch 214/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1721 - accuracy: 0.7514 - val_loss: 0.1692 - val_accuracy: 0.7000\n",
      "Epoch 215/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1720 - accuracy: 0.7514 - val_loss: 0.1695 - val_accuracy: 0.7000\n",
      "Epoch 216/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1719 - accuracy: 0.7514 - val_loss: 0.1698 - val_accuracy: 0.7000\n",
      "Epoch 217/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1719 - accuracy: 0.7572 - val_loss: 0.1694 - val_accuracy: 0.7000\n",
      "Epoch 218/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1718 - accuracy: 0.7572 - val_loss: 0.1701 - val_accuracy: 0.7000\n",
      "Epoch 219/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1717 - accuracy: 0.7457 - val_loss: 0.1708 - val_accuracy: 0.7000\n",
      "Epoch 220/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1717 - accuracy: 0.7514 - val_loss: 0.1712 - val_accuracy: 0.7000\n",
      "Epoch 221/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1714 - accuracy: 0.7514 - val_loss: 0.1706 - val_accuracy: 0.7000\n",
      "Epoch 222/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1715 - accuracy: 0.7572 - val_loss: 0.1700 - val_accuracy: 0.7000\n",
      "Epoch 223/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1714 - accuracy: 0.7572 - val_loss: 0.1705 - val_accuracy: 0.7000\n",
      "Epoch 224/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1713 - accuracy: 0.7514 - val_loss: 0.1708 - val_accuracy: 0.7000\n",
      "Epoch 225/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1712 - accuracy: 0.7457 - val_loss: 0.1708 - val_accuracy: 0.7000\n",
      "Epoch 226/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1711 - accuracy: 0.7514 - val_loss: 0.1708 - val_accuracy: 0.7000\n",
      "Epoch 227/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1712 - accuracy: 0.7514 - val_loss: 0.1699 - val_accuracy: 0.7000\n",
      "Epoch 228/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1710 - accuracy: 0.7514 - val_loss: 0.1702 - val_accuracy: 0.7000\n",
      "Epoch 229/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.7514 - val_loss: 0.1704 - val_accuracy: 0.7000\n",
      "Epoch 230/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.7514 - val_loss: 0.1707 - val_accuracy: 0.7000\n",
      "Epoch 231/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1707 - accuracy: 0.7514 - val_loss: 0.1708 - val_accuracy: 0.7000\n",
      "Epoch 232/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1706 - accuracy: 0.7514 - val_loss: 0.1709 - val_accuracy: 0.7000\n",
      "Epoch 233/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1705 - accuracy: 0.7514 - val_loss: 0.1710 - val_accuracy: 0.7000\n",
      "Epoch 234/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1704 - accuracy: 0.7457 - val_loss: 0.1711 - val_accuracy: 0.7000\n",
      "Epoch 235/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1704 - accuracy: 0.7457 - val_loss: 0.1713 - val_accuracy: 0.7000\n",
      "Epoch 236/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1702 - accuracy: 0.7514 - val_loss: 0.1713 - val_accuracy: 0.7000\n",
      "Epoch 237/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1702 - accuracy: 0.7514 - val_loss: 0.1714 - val_accuracy: 0.7000\n",
      "Epoch 238/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1702 - accuracy: 0.7457 - val_loss: 0.1718 - val_accuracy: 0.7000\n",
      "Epoch 239/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.7514 - val_loss: 0.1717 - val_accuracy: 0.7000\n",
      "Epoch 240/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.7514 - val_loss: 0.1714 - val_accuracy: 0.7000\n",
      "Epoch 241/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1700 - accuracy: 0.7457 - val_loss: 0.1715 - val_accuracy: 0.7000\n",
      "Epoch 242/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.7457 - val_loss: 0.1714 - val_accuracy: 0.7000\n",
      "Epoch 243/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1697 - accuracy: 0.7514 - val_loss: 0.1721 - val_accuracy: 0.7000\n",
      "Epoch 244/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1697 - accuracy: 0.7514 - val_loss: 0.1727 - val_accuracy: 0.7500\n",
      "Epoch 245/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1696 - accuracy: 0.7514 - val_loss: 0.1724 - val_accuracy: 0.7000\n",
      "Epoch 246/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1695 - accuracy: 0.7572 - val_loss: 0.1727 - val_accuracy: 0.7000\n",
      "Epoch 247/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1694 - accuracy: 0.7514 - val_loss: 0.1724 - val_accuracy: 0.7000\n",
      "Epoch 248/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1694 - accuracy: 0.7514 - val_loss: 0.1721 - val_accuracy: 0.7000\n",
      "Epoch 249/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1693 - accuracy: 0.7514 - val_loss: 0.1721 - val_accuracy: 0.7000\n",
      "Epoch 250/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1692 - accuracy: 0.7514 - val_loss: 0.1724 - val_accuracy: 0.7000\n",
      "Epoch 251/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1692 - accuracy: 0.7514 - val_loss: 0.1733 - val_accuracy: 0.7500\n",
      "Epoch 252/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.7514 - val_loss: 0.1734 - val_accuracy: 0.7500\n",
      "Epoch 253/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.7572 - val_loss: 0.1733 - val_accuracy: 0.7000\n",
      "Epoch 254/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1690 - accuracy: 0.7514 - val_loss: 0.1733 - val_accuracy: 0.7000\n",
      "Epoch 255/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1689 - accuracy: 0.7514 - val_loss: 0.1729 - val_accuracy: 0.7000\n",
      "Epoch 256/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1688 - accuracy: 0.7514 - val_loss: 0.1727 - val_accuracy: 0.7000\n",
      "Epoch 257/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1687 - accuracy: 0.7514 - val_loss: 0.1734 - val_accuracy: 0.7500\n",
      "Epoch 258/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1686 - accuracy: 0.7514 - val_loss: 0.1733 - val_accuracy: 0.7000\n",
      "Epoch 259/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1686 - accuracy: 0.7514 - val_loss: 0.1728 - val_accuracy: 0.7000\n",
      "Epoch 260/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1686 - accuracy: 0.7514 - val_loss: 0.1721 - val_accuracy: 0.7000\n",
      "Epoch 261/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1685 - accuracy: 0.7457 - val_loss: 0.1716 - val_accuracy: 0.7000\n",
      "Epoch 262/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1684 - accuracy: 0.7514 - val_loss: 0.1720 - val_accuracy: 0.7500\n",
      "Epoch 263/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.7514 - val_loss: 0.1724 - val_accuracy: 0.7500\n",
      "Epoch 264/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1682 - accuracy: 0.7514 - val_loss: 0.1727 - val_accuracy: 0.7500\n",
      "Epoch 265/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1681 - accuracy: 0.7630 - val_loss: 0.1732 - val_accuracy: 0.7500\n",
      "Epoch 266/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1682 - accuracy: 0.7572 - val_loss: 0.1733 - val_accuracy: 0.7500\n",
      "Epoch 267/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1681 - accuracy: 0.7572 - val_loss: 0.1730 - val_accuracy: 0.7500\n",
      "Epoch 268/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1679 - accuracy: 0.7630 - val_loss: 0.1731 - val_accuracy: 0.7500\n",
      "Epoch 269/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1678 - accuracy: 0.7572 - val_loss: 0.1739 - val_accuracy: 0.7500\n",
      "Epoch 270/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1677 - accuracy: 0.7572 - val_loss: 0.1740 - val_accuracy: 0.7500\n",
      "Epoch 271/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1677 - accuracy: 0.7572 - val_loss: 0.1741 - val_accuracy: 0.7500\n",
      "Epoch 272/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1678 - accuracy: 0.7572 - val_loss: 0.1752 - val_accuracy: 0.7500\n",
      "Epoch 273/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1676 - accuracy: 0.7572 - val_loss: 0.1748 - val_accuracy: 0.7500\n",
      "Epoch 274/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1676 - accuracy: 0.7514 - val_loss: 0.1743 - val_accuracy: 0.7500\n",
      "Epoch 275/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1674 - accuracy: 0.7572 - val_loss: 0.1745 - val_accuracy: 0.7500\n",
      "Epoch 276/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1673 - accuracy: 0.7630 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
      "Epoch 277/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1672 - accuracy: 0.7572 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 278/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1673 - accuracy: 0.7572 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 279/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1671 - accuracy: 0.7572 - val_loss: 0.1751 - val_accuracy: 0.7500\n",
      "Epoch 280/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1670 - accuracy: 0.7572 - val_loss: 0.1748 - val_accuracy: 0.7500\n",
      "Epoch 281/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1670 - accuracy: 0.7572 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 282/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1669 - accuracy: 0.7572 - val_loss: 0.1753 - val_accuracy: 0.7500\n",
      "Epoch 283/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1668 - accuracy: 0.7572 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 284/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.7572 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 285/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1668 - accuracy: 0.7514 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 286/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1667 - accuracy: 0.7514 - val_loss: 0.1767 - val_accuracy: 0.7500\n",
      "Epoch 287/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1667 - accuracy: 0.7514 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
      "Epoch 288/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1665 - accuracy: 0.7514 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 289/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1665 - accuracy: 0.7572 - val_loss: 0.1750 - val_accuracy: 0.7500\n",
      "Epoch 290/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1663 - accuracy: 0.7572 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 291/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1663 - accuracy: 0.7514 - val_loss: 0.1763 - val_accuracy: 0.7500\n",
      "Epoch 292/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1662 - accuracy: 0.7457 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 293/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1662 - accuracy: 0.7514 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 294/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1662 - accuracy: 0.7572 - val_loss: 0.1744 - val_accuracy: 0.7500\n",
      "Epoch 295/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1662 - accuracy: 0.7572 - val_loss: 0.1748 - val_accuracy: 0.7500\n",
      "Epoch 296/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1659 - accuracy: 0.7572 - val_loss: 0.1746 - val_accuracy: 0.7500\n",
      "Epoch 297/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1658 - accuracy: 0.7514 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 298/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1661 - accuracy: 0.7399 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 299/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1659 - accuracy: 0.7457 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 300/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1657 - accuracy: 0.7514 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 301/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1655 - accuracy: 0.7514 - val_loss: 0.1763 - val_accuracy: 0.7500\n",
      "Epoch 302/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1655 - accuracy: 0.7514 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 303/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1654 - accuracy: 0.7514 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 304/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1653 - accuracy: 0.7514 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
      "Epoch 305/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1653 - accuracy: 0.7514 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 306/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1652 - accuracy: 0.7572 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 307/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 0.7514 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 308/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1651 - accuracy: 0.7514 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 309/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1650 - accuracy: 0.7514 - val_loss: 0.1753 - val_accuracy: 0.7500\n",
      "Epoch 310/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.7514 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 311/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1648 - accuracy: 0.7514 - val_loss: 0.1759 - val_accuracy: 0.7500\n",
      "Epoch 312/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1648 - accuracy: 0.7514 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
      "Epoch 313/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1648 - accuracy: 0.7514 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 314/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1647 - accuracy: 0.7514 - val_loss: 0.1752 - val_accuracy: 0.7500\n",
      "Epoch 315/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1646 - accuracy: 0.7514 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 316/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1647 - accuracy: 0.7514 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 317/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1646 - accuracy: 0.7514 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 318/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1645 - accuracy: 0.7514 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 319/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1644 - accuracy: 0.7514 - val_loss: 0.1767 - val_accuracy: 0.7500\n",
      "Epoch 320/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1643 - accuracy: 0.7514 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 321/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1643 - accuracy: 0.7514 - val_loss: 0.1784 - val_accuracy: 0.7500\n",
      "Epoch 322/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1643 - accuracy: 0.7514 - val_loss: 0.1783 - val_accuracy: 0.7500\n",
      "Epoch 323/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1641 - accuracy: 0.7514 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
      "Epoch 324/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1641 - accuracy: 0.7514 - val_loss: 0.1763 - val_accuracy: 0.7500\n",
      "Epoch 325/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1642 - accuracy: 0.7514 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 326/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1645 - accuracy: 0.7514 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 327/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1639 - accuracy: 0.7514 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 328/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1639 - accuracy: 0.7457 - val_loss: 0.1789 - val_accuracy: 0.7500\n",
      "Epoch 329/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.7457 - val_loss: 0.1793 - val_accuracy: 0.7500\n",
      "Epoch 330/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1640 - accuracy: 0.7457 - val_loss: 0.1787 - val_accuracy: 0.7500\n",
      "Epoch 331/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1639 - accuracy: 0.7457 - val_loss: 0.1797 - val_accuracy: 0.7500\n",
      "Epoch 332/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1638 - accuracy: 0.7514 - val_loss: 0.1798 - val_accuracy: 0.7500\n",
      "Epoch 333/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1636 - accuracy: 0.7457 - val_loss: 0.1791 - val_accuracy: 0.7500\n",
      "Epoch 334/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1634 - accuracy: 0.7457 - val_loss: 0.1787 - val_accuracy: 0.7500\n",
      "Epoch 335/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1634 - accuracy: 0.7457 - val_loss: 0.1788 - val_accuracy: 0.7500\n",
      "Epoch 336/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1637 - accuracy: 0.7457 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 337/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1634 - accuracy: 0.7514 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
      "Epoch 338/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1634 - accuracy: 0.7514 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 339/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1633 - accuracy: 0.7514 - val_loss: 0.1774 - val_accuracy: 0.7500\n",
      "Epoch 340/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1630 - accuracy: 0.7514 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 341/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.7514 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 342/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1630 - accuracy: 0.7514 - val_loss: 0.1768 - val_accuracy: 0.7500\n",
      "Epoch 343/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.7514 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 344/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1632 - accuracy: 0.7514 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 345/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1628 - accuracy: 0.7514 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
      "Epoch 346/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1628 - accuracy: 0.7514 - val_loss: 0.1780 - val_accuracy: 0.7500\n",
      "Epoch 347/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1625 - accuracy: 0.7514 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 348/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1628 - accuracy: 0.7514 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
      "Epoch 349/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1626 - accuracy: 0.7514 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 350/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1625 - accuracy: 0.7514 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 351/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1625 - accuracy: 0.7514 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 352/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.7457 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 353/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.7457 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 354/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1623 - accuracy: 0.7457 - val_loss: 0.1773 - val_accuracy: 0.7500\n",
      "Epoch 355/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1624 - accuracy: 0.7514 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 356/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.7514 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 357/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1620 - accuracy: 0.7514 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
      "Epoch 358/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1619 - accuracy: 0.7514 - val_loss: 0.1781 - val_accuracy: 0.7500\n",
      "Epoch 359/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1622 - accuracy: 0.7514 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
      "Epoch 360/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1622 - accuracy: 0.7514 - val_loss: 0.1786 - val_accuracy: 0.7500\n",
      "Epoch 361/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1617 - accuracy: 0.7457 - val_loss: 0.1777 - val_accuracy: 0.7500\n",
      "Epoch 362/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1618 - accuracy: 0.7514 - val_loss: 0.1764 - val_accuracy: 0.7500\n",
      "Epoch 363/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1617 - accuracy: 0.7514 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 364/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1617 - accuracy: 0.7514 - val_loss: 0.1779 - val_accuracy: 0.7500\n",
      "Epoch 365/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1617 - accuracy: 0.7457 - val_loss: 0.1789 - val_accuracy: 0.7500\n",
      "Epoch 366/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1614 - accuracy: 0.7572 - val_loss: 0.1779 - val_accuracy: 0.7500\n",
      "Epoch 367/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1615 - accuracy: 0.7514 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 368/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1614 - accuracy: 0.7514 - val_loss: 0.1767 - val_accuracy: 0.7500\n",
      "Epoch 369/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1613 - accuracy: 0.7514 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 370/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1613 - accuracy: 0.7514 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 371/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1611 - accuracy: 0.7514 - val_loss: 0.1759 - val_accuracy: 0.7500\n",
      "Epoch 372/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1612 - accuracy: 0.7514 - val_loss: 0.1764 - val_accuracy: 0.7500\n",
      "Epoch 373/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1610 - accuracy: 0.7514 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 374/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1614 - accuracy: 0.7514 - val_loss: 0.1753 - val_accuracy: 0.7500\n",
      "Epoch 375/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1611 - accuracy: 0.7514 - val_loss: 0.1767 - val_accuracy: 0.7500\n",
      "Epoch 376/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 0.7514 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 377/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1609 - accuracy: 0.7514 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 378/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1608 - accuracy: 0.7514 - val_loss: 0.1764 - val_accuracy: 0.7500\n",
      "Epoch 379/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1608 - accuracy: 0.7514 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
      "Epoch 380/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1607 - accuracy: 0.7514 - val_loss: 0.1777 - val_accuracy: 0.7500\n",
      "Epoch 381/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1606 - accuracy: 0.7514 - val_loss: 0.1763 - val_accuracy: 0.7500\n",
      "Epoch 382/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1605 - accuracy: 0.7514 - val_loss: 0.1752 - val_accuracy: 0.7500\n",
      "Epoch 383/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1604 - accuracy: 0.7572 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 384/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1605 - accuracy: 0.7572 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 385/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1603 - accuracy: 0.7572 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 386/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1603 - accuracy: 0.7572 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 387/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1602 - accuracy: 0.7572 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 388/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1602 - accuracy: 0.7630 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 389/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1600 - accuracy: 0.7630 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 390/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1600 - accuracy: 0.7746 - val_loss: 0.1785 - val_accuracy: 0.7500\n",
      "Epoch 391/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1600 - accuracy: 0.7746 - val_loss: 0.1785 - val_accuracy: 0.7500\n",
      "Epoch 392/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 0.7746 - val_loss: 0.1787 - val_accuracy: 0.7500\n",
      "Epoch 393/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 0.7746 - val_loss: 0.1789 - val_accuracy: 0.7500\n",
      "Epoch 394/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1599 - accuracy: 0.7746 - val_loss: 0.1789 - val_accuracy: 0.7500\n",
      "Epoch 395/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1597 - accuracy: 0.7746 - val_loss: 0.1777 - val_accuracy: 0.7500\n",
      "Epoch 396/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1598 - accuracy: 0.7630 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 397/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1596 - accuracy: 0.7630 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 398/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1595 - accuracy: 0.7630 - val_loss: 0.1780 - val_accuracy: 0.7500\n",
      "Epoch 399/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1595 - accuracy: 0.7688 - val_loss: 0.1778 - val_accuracy: 0.7500\n",
      "Epoch 400/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.7688 - val_loss: 0.1782 - val_accuracy: 0.7500\n",
      "Epoch 401/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.7688 - val_loss: 0.1778 - val_accuracy: 0.7500\n",
      "Epoch 402/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.7688 - val_loss: 0.1777 - val_accuracy: 0.7500\n",
      "Epoch 403/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.7630 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 404/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.7630 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 405/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1590 - accuracy: 0.7630 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 406/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.7803 - val_loss: 0.1794 - val_accuracy: 0.7500\n",
      "Epoch 407/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.7861 - val_loss: 0.1803 - val_accuracy: 0.7500\n",
      "Epoch 408/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1591 - accuracy: 0.7803 - val_loss: 0.1785 - val_accuracy: 0.7500\n",
      "Epoch 409/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1588 - accuracy: 0.7746 - val_loss: 0.1774 - val_accuracy: 0.7500\n",
      "Epoch 410/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1589 - accuracy: 0.7746 - val_loss: 0.1773 - val_accuracy: 0.7500\n",
      "Epoch 411/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1587 - accuracy: 0.7746 - val_loss: 0.1780 - val_accuracy: 0.7500\n",
      "Epoch 412/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1589 - accuracy: 0.7803 - val_loss: 0.1793 - val_accuracy: 0.7500\n",
      "Epoch 413/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1587 - accuracy: 0.7803 - val_loss: 0.1796 - val_accuracy: 0.7500\n",
      "Epoch 414/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1585 - accuracy: 0.7746 - val_loss: 0.1787 - val_accuracy: 0.7500\n",
      "Epoch 415/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1586 - accuracy: 0.7746 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 416/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1584 - accuracy: 0.7746 - val_loss: 0.1777 - val_accuracy: 0.7500\n",
      "Epoch 417/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1582 - accuracy: 0.7746 - val_loss: 0.1782 - val_accuracy: 0.7500\n",
      "Epoch 418/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1583 - accuracy: 0.7803 - val_loss: 0.1785 - val_accuracy: 0.7500\n",
      "Epoch 419/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.7746 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 420/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1581 - accuracy: 0.7746 - val_loss: 0.1768 - val_accuracy: 0.7500\n",
      "Epoch 421/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1581 - accuracy: 0.7746 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 422/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1580 - accuracy: 0.7746 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 423/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1580 - accuracy: 0.7688 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 424/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1580 - accuracy: 0.7861 - val_loss: 0.1773 - val_accuracy: 0.7500\n",
      "Epoch 425/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1578 - accuracy: 0.7861 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 426/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1578 - accuracy: 0.7861 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 427/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1577 - accuracy: 0.7861 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 428/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1577 - accuracy: 0.7861 - val_loss: 0.1760 - val_accuracy: 0.7500\n",
      "Epoch 429/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1576 - accuracy: 0.7861 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 430/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1575 - accuracy: 0.7861 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 431/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1576 - accuracy: 0.7630 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
      "Epoch 432/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1574 - accuracy: 0.7630 - val_loss: 0.1759 - val_accuracy: 0.7500\n",
      "Epoch 433/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1573 - accuracy: 0.7861 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 434/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1572 - accuracy: 0.7861 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
      "Epoch 435/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1574 - accuracy: 0.7861 - val_loss: 0.1760 - val_accuracy: 0.7500\n",
      "Epoch 436/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1573 - accuracy: 0.7861 - val_loss: 0.1753 - val_accuracy: 0.7500\n",
      "Epoch 437/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1570 - accuracy: 0.7861 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 438/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1572 - accuracy: 0.7803 - val_loss: 0.1781 - val_accuracy: 0.7500\n",
      "Epoch 439/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1571 - accuracy: 0.7861 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 440/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.7861 - val_loss: 0.1767 - val_accuracy: 0.7500\n",
      "Epoch 441/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1568 - accuracy: 0.7861 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 442/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1568 - accuracy: 0.7861 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
      "Epoch 443/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.7861 - val_loss: 0.1772 - val_accuracy: 0.7500\n",
      "Epoch 444/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1566 - accuracy: 0.7861 - val_loss: 0.1772 - val_accuracy: 0.7500\n",
      "Epoch 445/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1565 - accuracy: 0.7861 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 446/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1564 - accuracy: 0.7861 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 447/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.7861 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 448/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1563 - accuracy: 0.7861 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 449/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1564 - accuracy: 0.7861 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 450/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1561 - accuracy: 0.7861 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 451/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1561 - accuracy: 0.7861 - val_loss: 0.1749 - val_accuracy: 0.7500\n",
      "Epoch 452/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1562 - accuracy: 0.7746 - val_loss: 0.1750 - val_accuracy: 0.7500\n",
      "Epoch 453/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1562 - accuracy: 0.7688 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 454/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1560 - accuracy: 0.7861 - val_loss: 0.1777 - val_accuracy: 0.7500\n",
      "Epoch 455/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1561 - accuracy: 0.7803 - val_loss: 0.1787 - val_accuracy: 0.7500\n",
      "Epoch 456/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1558 - accuracy: 0.7746 - val_loss: 0.1779 - val_accuracy: 0.7500\n",
      "Epoch 457/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1556 - accuracy: 0.7861 - val_loss: 0.1759 - val_accuracy: 0.7500\n",
      "Epoch 458/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1557 - accuracy: 0.7919 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
      "Epoch 459/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1558 - accuracy: 0.7803 - val_loss: 0.1750 - val_accuracy: 0.7500\n",
      "Epoch 460/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1555 - accuracy: 0.7861 - val_loss: 0.1767 - val_accuracy: 0.7500\n",
      "Epoch 461/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1554 - accuracy: 0.7861 - val_loss: 0.1773 - val_accuracy: 0.7500\n",
      "Epoch 462/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.7803 - val_loss: 0.1772 - val_accuracy: 0.7500\n",
      "Epoch 463/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1553 - accuracy: 0.7803 - val_loss: 0.1782 - val_accuracy: 0.7500\n",
      "Epoch 464/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1552 - accuracy: 0.7803 - val_loss: 0.1773 - val_accuracy: 0.7500\n",
      "Epoch 465/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1552 - accuracy: 0.7803 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 466/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1551 - accuracy: 0.7803 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 467/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1549 - accuracy: 0.7861 - val_loss: 0.1760 - val_accuracy: 0.7500\n",
      "Epoch 468/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1551 - accuracy: 0.7861 - val_loss: 0.1751 - val_accuracy: 0.7500\n",
      "Epoch 469/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1551 - accuracy: 0.7861 - val_loss: 0.1767 - val_accuracy: 0.7500\n",
      "Epoch 470/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.7803 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 471/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.7803 - val_loss: 0.1781 - val_accuracy: 0.7500\n",
      "Epoch 472/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.7803 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 473/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1547 - accuracy: 0.7803 - val_loss: 0.1779 - val_accuracy: 0.7500\n",
      "Epoch 474/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1550 - accuracy: 0.7803 - val_loss: 0.1753 - val_accuracy: 0.7500\n",
      "Epoch 475/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1546 - accuracy: 0.7861 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 476/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1544 - accuracy: 0.7803 - val_loss: 0.1779 - val_accuracy: 0.7500\n",
      "Epoch 477/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1543 - accuracy: 0.7803 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 478/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1542 - accuracy: 0.7803 - val_loss: 0.1772 - val_accuracy: 0.7500\n",
      "Epoch 479/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1541 - accuracy: 0.7803 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 480/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1542 - accuracy: 0.7803 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
      "Epoch 481/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1540 - accuracy: 0.7803 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
      "Epoch 482/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1539 - accuracy: 0.7746 - val_loss: 0.1779 - val_accuracy: 0.7500\n",
      "Epoch 483/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1539 - accuracy: 0.7746 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 484/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1537 - accuracy: 0.7803 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 485/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1535 - accuracy: 0.7803 - val_loss: 0.1774 - val_accuracy: 0.7500\n",
      "Epoch 486/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1534 - accuracy: 0.7746 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 487/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1534 - accuracy: 0.7746 - val_loss: 0.1773 - val_accuracy: 0.7500\n",
      "Epoch 488/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1531 - accuracy: 0.7746 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
      "Epoch 489/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.7803 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
      "Epoch 490/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1530 - accuracy: 0.7803 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 491/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1528 - accuracy: 0.7803 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 492/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1527 - accuracy: 0.7803 - val_loss: 0.1773 - val_accuracy: 0.7500\n",
      "Epoch 493/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1530 - accuracy: 0.7746 - val_loss: 0.1759 - val_accuracy: 0.7500\n",
      "Epoch 494/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1526 - accuracy: 0.7803 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 495/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1525 - accuracy: 0.7746 - val_loss: 0.1760 - val_accuracy: 0.7500\n",
      "Epoch 496/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1524 - accuracy: 0.7803 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 497/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1523 - accuracy: 0.7803 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 498/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1522 - accuracy: 0.7803 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 499/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1521 - accuracy: 0.7746 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 500/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1521 - accuracy: 0.7746 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 501/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1520 - accuracy: 0.7746 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 502/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1519 - accuracy: 0.7746 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 503/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1521 - accuracy: 0.7746 - val_loss: 0.1781 - val_accuracy: 0.7500\n",
      "Epoch 504/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1519 - accuracy: 0.7746 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 505/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1517 - accuracy: 0.7746 - val_loss: 0.1752 - val_accuracy: 0.7500\n",
      "Epoch 506/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1516 - accuracy: 0.7803 - val_loss: 0.1751 - val_accuracy: 0.7500\n",
      "Epoch 507/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1515 - accuracy: 0.7803 - val_loss: 0.1753 - val_accuracy: 0.7500\n",
      "Epoch 508/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1514 - accuracy: 0.7746 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 509/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1514 - accuracy: 0.7746 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
      "Epoch 510/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1513 - accuracy: 0.7746 - val_loss: 0.1777 - val_accuracy: 0.7500\n",
      "Epoch 511/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1513 - accuracy: 0.7746 - val_loss: 0.1763 - val_accuracy: 0.7500\n",
      "Epoch 512/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1510 - accuracy: 0.7746 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
      "Epoch 513/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1510 - accuracy: 0.7746 - val_loss: 0.1775 - val_accuracy: 0.7500\n",
      "Epoch 514/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1510 - accuracy: 0.7746 - val_loss: 0.1772 - val_accuracy: 0.7500\n",
      "Epoch 515/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1507 - accuracy: 0.7746 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 516/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1508 - accuracy: 0.7746 - val_loss: 0.1745 - val_accuracy: 0.7500\n",
      "Epoch 517/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1507 - accuracy: 0.7861 - val_loss: 0.1746 - val_accuracy: 0.7500\n",
      "Epoch 518/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1505 - accuracy: 0.7746 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 519/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1503 - accuracy: 0.7803 - val_loss: 0.1767 - val_accuracy: 0.7500\n",
      "Epoch 520/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1504 - accuracy: 0.7803 - val_loss: 0.1771 - val_accuracy: 0.7500\n",
      "Epoch 521/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1503 - accuracy: 0.7803 - val_loss: 0.1761 - val_accuracy: 0.7500\n",
      "Epoch 522/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1501 - accuracy: 0.7803 - val_loss: 0.1753 - val_accuracy: 0.7500\n",
      "Epoch 523/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1502 - accuracy: 0.7746 - val_loss: 0.1746 - val_accuracy: 0.7500\n",
      "Epoch 524/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1498 - accuracy: 0.7746 - val_loss: 0.1763 - val_accuracy: 0.7500\n",
      "Epoch 525/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1498 - accuracy: 0.7746 - val_loss: 0.1783 - val_accuracy: 0.7500\n",
      "Epoch 526/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1500 - accuracy: 0.7746 - val_loss: 0.1794 - val_accuracy: 0.7500\n",
      "Epoch 527/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1499 - accuracy: 0.7746 - val_loss: 0.1787 - val_accuracy: 0.7500\n",
      "Epoch 528/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1496 - accuracy: 0.7861 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 529/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.7803 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 530/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.7803 - val_loss: 0.1748 - val_accuracy: 0.7500\n",
      "Epoch 531/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1495 - accuracy: 0.7861 - val_loss: 0.1748 - val_accuracy: 0.7500\n",
      "Epoch 532/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1494 - accuracy: 0.7803 - val_loss: 0.1746 - val_accuracy: 0.7500\n",
      "Epoch 533/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1495 - accuracy: 0.7688 - val_loss: 0.1758 - val_accuracy: 0.7500\n",
      "Epoch 534/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1491 - accuracy: 0.7688 - val_loss: 0.1752 - val_accuracy: 0.7500\n",
      "Epoch 535/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1492 - accuracy: 0.7803 - val_loss: 0.1759 - val_accuracy: 0.7500\n",
      "Epoch 536/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.7803 - val_loss: 0.1746 - val_accuracy: 0.7500\n",
      "Epoch 537/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.7861 - val_loss: 0.1753 - val_accuracy: 0.7500\n",
      "Epoch 538/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.7803 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 539/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1488 - accuracy: 0.7977 - val_loss: 0.1748 - val_accuracy: 0.7500\n",
      "Epoch 540/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1485 - accuracy: 0.7977 - val_loss: 0.1756 - val_accuracy: 0.7500\n",
      "Epoch 541/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.7861 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 542/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.7688 - val_loss: 0.1787 - val_accuracy: 0.7500\n",
      "Epoch 543/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1486 - accuracy: 0.7746 - val_loss: 0.1782 - val_accuracy: 0.7500\n",
      "Epoch 544/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1483 - accuracy: 0.7688 - val_loss: 0.1768 - val_accuracy: 0.7500\n",
      "Epoch 545/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1480 - accuracy: 0.7803 - val_loss: 0.1744 - val_accuracy: 0.7500\n",
      "Epoch 546/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1486 - accuracy: 0.8035 - val_loss: 0.1744 - val_accuracy: 0.7500\n",
      "Epoch 547/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1491 - accuracy: 0.7861 - val_loss: 0.1783 - val_accuracy: 0.7500\n",
      "Epoch 548/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1482 - accuracy: 0.7746 - val_loss: 0.1777 - val_accuracy: 0.7500\n",
      "Epoch 549/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1484 - accuracy: 0.7746 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 550/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1478 - accuracy: 0.7746 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 551/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1476 - accuracy: 0.7861 - val_loss: 0.1753 - val_accuracy: 0.7500\n",
      "Epoch 552/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1478 - accuracy: 0.7919 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 553/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1473 - accuracy: 0.7861 - val_loss: 0.1751 - val_accuracy: 0.7500\n",
      "Epoch 554/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1477 - accuracy: 0.7919 - val_loss: 0.1738 - val_accuracy: 0.7500\n",
      "Epoch 555/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1474 - accuracy: 0.7977 - val_loss: 0.1748 - val_accuracy: 0.7500\n",
      "Epoch 556/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1477 - accuracy: 0.7746 - val_loss: 0.1781 - val_accuracy: 0.7500\n",
      "Epoch 557/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1472 - accuracy: 0.7746 - val_loss: 0.1773 - val_accuracy: 0.7500\n",
      "Epoch 558/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1472 - accuracy: 0.7803 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 559/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1471 - accuracy: 0.7746 - val_loss: 0.1772 - val_accuracy: 0.7500\n",
      "Epoch 560/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1470 - accuracy: 0.7746 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 561/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1468 - accuracy: 0.7861 - val_loss: 0.1770 - val_accuracy: 0.7500\n",
      "Epoch 562/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1467 - accuracy: 0.7861 - val_loss: 0.1763 - val_accuracy: 0.7500\n",
      "Epoch 563/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1465 - accuracy: 0.7919 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
      "Epoch 564/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1465 - accuracy: 0.7919 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
      "Epoch 565/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1470 - accuracy: 0.7977 - val_loss: 0.1745 - val_accuracy: 0.7500\n",
      "Epoch 566/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1463 - accuracy: 0.7861 - val_loss: 0.1762 - val_accuracy: 0.7500\n",
      "Epoch 567/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1464 - accuracy: 0.7919 - val_loss: 0.1774 - val_accuracy: 0.7500\n",
      "Epoch 568/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1461 - accuracy: 0.7977 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 569/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1460 - accuracy: 0.7919 - val_loss: 0.1767 - val_accuracy: 0.7500\n",
      "Epoch 570/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1460 - accuracy: 0.7861 - val_loss: 0.1764 - val_accuracy: 0.7500\n",
      "Epoch 571/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1460 - accuracy: 0.7919 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
      "Epoch 572/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1458 - accuracy: 0.7977 - val_loss: 0.1757 - val_accuracy: 0.7500\n",
      "Epoch 573/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1459 - accuracy: 0.7919 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 574/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1456 - accuracy: 0.7977 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 575/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1455 - accuracy: 0.7977 - val_loss: 0.1766 - val_accuracy: 0.7500\n",
      "Epoch 576/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1453 - accuracy: 0.7977 - val_loss: 0.1782 - val_accuracy: 0.7500\n",
      "Epoch 577/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1452 - accuracy: 0.7919 - val_loss: 0.1785 - val_accuracy: 0.7500\n",
      "Epoch 578/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.7977 - val_loss: 0.1776 - val_accuracy: 0.7500\n",
      "Epoch 579/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1451 - accuracy: 0.7977 - val_loss: 0.1754 - val_accuracy: 0.7500\n",
      "Epoch 580/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.7977 - val_loss: 0.1765 - val_accuracy: 0.7500\n",
      "Epoch 581/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1447 - accuracy: 0.7977 - val_loss: 0.1752 - val_accuracy: 0.7500\n",
      "Epoch 582/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1448 - accuracy: 0.7977 - val_loss: 0.1732 - val_accuracy: 0.7500\n",
      "Epoch 583/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1444 - accuracy: 0.7977 - val_loss: 0.1747 - val_accuracy: 0.7500\n",
      "Epoch 584/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1442 - accuracy: 0.8035 - val_loss: 0.1755 - val_accuracy: 0.7500\n",
      "Epoch 585/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1443 - accuracy: 0.8035 - val_loss: 0.1746 - val_accuracy: 0.7500\n",
      "Epoch 586/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1440 - accuracy: 0.8035 - val_loss: 0.1764 - val_accuracy: 0.7500\n",
      "Epoch 587/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.7977 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 588/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.7977 - val_loss: 0.1748 - val_accuracy: 0.7500\n",
      "Epoch 589/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1435 - accuracy: 0.8035 - val_loss: 0.1737 - val_accuracy: 0.7500\n",
      "Epoch 590/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1436 - accuracy: 0.7977 - val_loss: 0.1730 - val_accuracy: 0.7500\n",
      "Epoch 591/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1434 - accuracy: 0.8035 - val_loss: 0.1729 - val_accuracy: 0.7500\n",
      "Epoch 592/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.8035 - val_loss: 0.1731 - val_accuracy: 0.7500\n",
      "Epoch 593/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1429 - accuracy: 0.8092 - val_loss: 0.1733 - val_accuracy: 0.7500\n",
      "Epoch 594/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1429 - accuracy: 0.8035 - val_loss: 0.1723 - val_accuracy: 0.7500\n",
      "Epoch 595/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1426 - accuracy: 0.8035 - val_loss: 0.1730 - val_accuracy: 0.7500\n",
      "Epoch 596/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1425 - accuracy: 0.8092 - val_loss: 0.1739 - val_accuracy: 0.7500\n",
      "Epoch 597/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1427 - accuracy: 0.7977 - val_loss: 0.1748 - val_accuracy: 0.7500\n",
      "Epoch 598/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1424 - accuracy: 0.8092 - val_loss: 0.1734 - val_accuracy: 0.7500\n",
      "Epoch 599/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1422 - accuracy: 0.8035 - val_loss: 0.1697 - val_accuracy: 0.7500\n",
      "Epoch 600/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1423 - accuracy: 0.8092 - val_loss: 0.1685 - val_accuracy: 0.7500\n",
      "Epoch 601/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1420 - accuracy: 0.8150 - val_loss: 0.1699 - val_accuracy: 0.7500\n",
      "Epoch 602/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1416 - accuracy: 0.8035 - val_loss: 0.1711 - val_accuracy: 0.7500\n",
      "Epoch 603/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1417 - accuracy: 0.7977 - val_loss: 0.1735 - val_accuracy: 0.7500\n",
      "Epoch 604/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1414 - accuracy: 0.8035 - val_loss: 0.1719 - val_accuracy: 0.7500\n",
      "Epoch 605/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1411 - accuracy: 0.7977 - val_loss: 0.1708 - val_accuracy: 0.7500\n",
      "Epoch 606/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1411 - accuracy: 0.7977 - val_loss: 0.1693 - val_accuracy: 0.7500\n",
      "Epoch 607/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1411 - accuracy: 0.7977 - val_loss: 0.1698 - val_accuracy: 0.7500\n",
      "Epoch 608/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1406 - accuracy: 0.7977 - val_loss: 0.1751 - val_accuracy: 0.7500\n",
      "Epoch 609/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1411 - accuracy: 0.7977 - val_loss: 0.1769 - val_accuracy: 0.7500\n",
      "Epoch 610/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1410 - accuracy: 0.8035 - val_loss: 0.1734 - val_accuracy: 0.7500\n",
      "Epoch 611/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.8092 - val_loss: 0.1710 - val_accuracy: 0.7500\n",
      "Epoch 612/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1403 - accuracy: 0.8150 - val_loss: 0.1695 - val_accuracy: 0.7500\n",
      "Epoch 613/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1403 - accuracy: 0.8092 - val_loss: 0.1693 - val_accuracy: 0.7500\n",
      "Epoch 614/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1402 - accuracy: 0.8092 - val_loss: 0.1698 - val_accuracy: 0.7500\n",
      "Epoch 615/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.8092 - val_loss: 0.1732 - val_accuracy: 0.7500\n",
      "Epoch 616/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.8035 - val_loss: 0.1745 - val_accuracy: 0.7500\n",
      "Epoch 617/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1398 - accuracy: 0.8035 - val_loss: 0.1736 - val_accuracy: 0.7500\n",
      "Epoch 618/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1400 - accuracy: 0.8150 - val_loss: 0.1718 - val_accuracy: 0.7500\n",
      "Epoch 619/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1395 - accuracy: 0.8092 - val_loss: 0.1714 - val_accuracy: 0.7500\n",
      "Epoch 620/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1394 - accuracy: 0.8035 - val_loss: 0.1701 - val_accuracy: 0.7500\n",
      "Epoch 621/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1393 - accuracy: 0.8035 - val_loss: 0.1709 - val_accuracy: 0.7500\n",
      "Epoch 622/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1390 - accuracy: 0.8035 - val_loss: 0.1702 - val_accuracy: 0.7500\n",
      "Epoch 623/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1388 - accuracy: 0.8035 - val_loss: 0.1707 - val_accuracy: 0.7500\n",
      "Epoch 624/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1387 - accuracy: 0.8150 - val_loss: 0.1713 - val_accuracy: 0.7500\n",
      "Epoch 625/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1388 - accuracy: 0.8208 - val_loss: 0.1717 - val_accuracy: 0.7500\n",
      "Epoch 626/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1386 - accuracy: 0.8092 - val_loss: 0.1703 - val_accuracy: 0.7500\n",
      "Epoch 627/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.8092 - val_loss: 0.1698 - val_accuracy: 0.7500\n",
      "Epoch 628/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1386 - accuracy: 0.7977 - val_loss: 0.1704 - val_accuracy: 0.7500\n",
      "Epoch 629/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.8035 - val_loss: 0.1673 - val_accuracy: 0.7500\n",
      "Epoch 630/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1381 - accuracy: 0.8382 - val_loss: 0.1663 - val_accuracy: 0.7500\n",
      "Epoch 631/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1379 - accuracy: 0.8324 - val_loss: 0.1672 - val_accuracy: 0.7500\n",
      "Epoch 632/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1377 - accuracy: 0.8266 - val_loss: 0.1684 - val_accuracy: 0.7500\n",
      "Epoch 633/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1375 - accuracy: 0.8266 - val_loss: 0.1681 - val_accuracy: 0.7500\n",
      "Epoch 634/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.8266 - val_loss: 0.1693 - val_accuracy: 0.7500\n",
      "Epoch 635/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1374 - accuracy: 0.8150 - val_loss: 0.1706 - val_accuracy: 0.7500\n",
      "Epoch 636/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1372 - accuracy: 0.8150 - val_loss: 0.1700 - val_accuracy: 0.7500\n",
      "Epoch 637/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1370 - accuracy: 0.8266 - val_loss: 0.1693 - val_accuracy: 0.7500\n",
      "Epoch 638/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1372 - accuracy: 0.8266 - val_loss: 0.1663 - val_accuracy: 0.7500\n",
      "Epoch 639/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.8324 - val_loss: 0.1669 - val_accuracy: 0.7500\n",
      "Epoch 640/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1366 - accuracy: 0.8266 - val_loss: 0.1672 - val_accuracy: 0.7500\n",
      "Epoch 641/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1365 - accuracy: 0.8266 - val_loss: 0.1679 - val_accuracy: 0.7500\n",
      "Epoch 642/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1365 - accuracy: 0.8266 - val_loss: 0.1692 - val_accuracy: 0.7500\n",
      "Epoch 643/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1362 - accuracy: 0.8266 - val_loss: 0.1689 - val_accuracy: 0.7500\n",
      "Epoch 644/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1360 - accuracy: 0.8324 - val_loss: 0.1680 - val_accuracy: 0.7500\n",
      "Epoch 645/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 0.8324 - val_loss: 0.1669 - val_accuracy: 0.7500\n",
      "Epoch 646/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1358 - accuracy: 0.8324 - val_loss: 0.1663 - val_accuracy: 0.7500\n",
      "Epoch 647/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1359 - accuracy: 0.8266 - val_loss: 0.1647 - val_accuracy: 0.8000\n",
      "Epoch 648/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1356 - accuracy: 0.8266 - val_loss: 0.1658 - val_accuracy: 0.7500\n",
      "Epoch 649/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.8208 - val_loss: 0.1678 - val_accuracy: 0.7500\n",
      "Epoch 650/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1356 - accuracy: 0.8208 - val_loss: 0.1687 - val_accuracy: 0.7500\n",
      "Epoch 651/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.8208 - val_loss: 0.1688 - val_accuracy: 0.7500\n",
      "Epoch 652/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1351 - accuracy: 0.8266 - val_loss: 0.1669 - val_accuracy: 0.7500\n",
      "Epoch 653/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1348 - accuracy: 0.8324 - val_loss: 0.1661 - val_accuracy: 0.8000\n",
      "Epoch 654/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1348 - accuracy: 0.8324 - val_loss: 0.1655 - val_accuracy: 0.8000\n",
      "Epoch 655/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1348 - accuracy: 0.8266 - val_loss: 0.1662 - val_accuracy: 0.8000\n",
      "Epoch 656/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1348 - accuracy: 0.8266 - val_loss: 0.1676 - val_accuracy: 0.8000\n",
      "Epoch 657/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1343 - accuracy: 0.8266 - val_loss: 0.1672 - val_accuracy: 0.8000\n",
      "Epoch 658/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1342 - accuracy: 0.8266 - val_loss: 0.1662 - val_accuracy: 0.8000\n",
      "Epoch 659/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1340 - accuracy: 0.8324 - val_loss: 0.1641 - val_accuracy: 0.8000\n",
      "Epoch 660/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1338 - accuracy: 0.8324 - val_loss: 0.1637 - val_accuracy: 0.8000\n",
      "Epoch 661/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1337 - accuracy: 0.8324 - val_loss: 0.1636 - val_accuracy: 0.8000\n",
      "Epoch 662/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.8266 - val_loss: 0.1659 - val_accuracy: 0.7500\n",
      "Epoch 663/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.8266 - val_loss: 0.1671 - val_accuracy: 0.7500\n",
      "Epoch 664/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1331 - accuracy: 0.8266 - val_loss: 0.1655 - val_accuracy: 0.8000\n",
      "Epoch 665/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1333 - accuracy: 0.8208 - val_loss: 0.1639 - val_accuracy: 0.8000\n",
      "Epoch 666/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1331 - accuracy: 0.8208 - val_loss: 0.1649 - val_accuracy: 0.8000\n",
      "Epoch 667/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.8324 - val_loss: 0.1637 - val_accuracy: 0.8000\n",
      "Epoch 668/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1326 - accuracy: 0.8266 - val_loss: 0.1630 - val_accuracy: 0.8000\n",
      "Epoch 669/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1325 - accuracy: 0.8266 - val_loss: 0.1638 - val_accuracy: 0.8000\n",
      "Epoch 670/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 0.8266 - val_loss: 0.1648 - val_accuracy: 0.8000\n",
      "Epoch 671/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1324 - accuracy: 0.8266 - val_loss: 0.1651 - val_accuracy: 0.8000\n",
      "Epoch 672/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1320 - accuracy: 0.8324 - val_loss: 0.1629 - val_accuracy: 0.8000\n",
      "Epoch 673/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.8266 - val_loss: 0.1632 - val_accuracy: 0.8000\n",
      "Epoch 674/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1319 - accuracy: 0.8324 - val_loss: 0.1630 - val_accuracy: 0.8000\n",
      "Epoch 675/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1322 - accuracy: 0.8324 - val_loss: 0.1614 - val_accuracy: 0.8000\n",
      "Epoch 676/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1320 - accuracy: 0.8324 - val_loss: 0.1627 - val_accuracy: 0.8000\n",
      "Epoch 677/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1313 - accuracy: 0.8266 - val_loss: 0.1632 - val_accuracy: 0.8000\n",
      "Epoch 678/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1312 - accuracy: 0.8208 - val_loss: 0.1639 - val_accuracy: 0.8000\n",
      "Epoch 679/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1312 - accuracy: 0.8266 - val_loss: 0.1622 - val_accuracy: 0.8000\n",
      "Epoch 680/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.8324 - val_loss: 0.1621 - val_accuracy: 0.8000\n",
      "Epoch 681/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1309 - accuracy: 0.8324 - val_loss: 0.1635 - val_accuracy: 0.8000\n",
      "Epoch 682/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.8266 - val_loss: 0.1632 - val_accuracy: 0.8000\n",
      "Epoch 683/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1304 - accuracy: 0.8266 - val_loss: 0.1620 - val_accuracy: 0.8000\n",
      "Epoch 684/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1304 - accuracy: 0.8324 - val_loss: 0.1610 - val_accuracy: 0.8000\n",
      "Epoch 685/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1305 - accuracy: 0.8266 - val_loss: 0.1609 - val_accuracy: 0.8000\n",
      "Epoch 686/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1303 - accuracy: 0.8266 - val_loss: 0.1639 - val_accuracy: 0.8000\n",
      "Epoch 687/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1299 - accuracy: 0.8266 - val_loss: 0.1642 - val_accuracy: 0.8000\n",
      "Epoch 688/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1298 - accuracy: 0.8324 - val_loss: 0.1642 - val_accuracy: 0.8000\n",
      "Epoch 689/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1299 - accuracy: 0.8324 - val_loss: 0.1629 - val_accuracy: 0.8000\n",
      "Epoch 690/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1296 - accuracy: 0.8324 - val_loss: 0.1614 - val_accuracy: 0.8000\n",
      "Epoch 691/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.8266 - val_loss: 0.1608 - val_accuracy: 0.8000\n",
      "Epoch 692/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1291 - accuracy: 0.8266 - val_loss: 0.1600 - val_accuracy: 0.8000\n",
      "Epoch 693/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.8208 - val_loss: 0.1587 - val_accuracy: 0.8000\n",
      "Epoch 694/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1290 - accuracy: 0.8208 - val_loss: 0.1606 - val_accuracy: 0.8000\n",
      "Epoch 695/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.8208 - val_loss: 0.1606 - val_accuracy: 0.8000\n",
      "Epoch 696/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1289 - accuracy: 0.8208 - val_loss: 0.1621 - val_accuracy: 0.8000\n",
      "Epoch 697/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1288 - accuracy: 0.8208 - val_loss: 0.1618 - val_accuracy: 0.8000\n",
      "Epoch 698/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.8150 - val_loss: 0.1646 - val_accuracy: 0.8000\n",
      "Epoch 699/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1285 - accuracy: 0.8208 - val_loss: 0.1641 - val_accuracy: 0.8000\n",
      "Epoch 700/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1282 - accuracy: 0.8208 - val_loss: 0.1630 - val_accuracy: 0.8000\n",
      "Epoch 701/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.8266 - val_loss: 0.1633 - val_accuracy: 0.8000\n",
      "Epoch 702/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1280 - accuracy: 0.8266 - val_loss: 0.1624 - val_accuracy: 0.8000\n",
      "Epoch 703/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1277 - accuracy: 0.8266 - val_loss: 0.1633 - val_accuracy: 0.8000\n",
      "Epoch 704/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1278 - accuracy: 0.8324 - val_loss: 0.1637 - val_accuracy: 0.8000\n",
      "Epoch 705/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1274 - accuracy: 0.8324 - val_loss: 0.1620 - val_accuracy: 0.8000\n",
      "Epoch 706/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1271 - accuracy: 0.8382 - val_loss: 0.1599 - val_accuracy: 0.8000\n",
      "Epoch 707/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1274 - accuracy: 0.8324 - val_loss: 0.1583 - val_accuracy: 0.8000\n",
      "Epoch 708/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1275 - accuracy: 0.8266 - val_loss: 0.1592 - val_accuracy: 0.8000\n",
      "Epoch 709/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1271 - accuracy: 0.8382 - val_loss: 0.1594 - val_accuracy: 0.8000\n",
      "Epoch 710/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1268 - accuracy: 0.8439 - val_loss: 0.1604 - val_accuracy: 0.8000\n",
      "Epoch 711/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1272 - accuracy: 0.8324 - val_loss: 0.1622 - val_accuracy: 0.8000\n",
      "Epoch 712/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.8382 - val_loss: 0.1600 - val_accuracy: 0.8000\n",
      "Epoch 713/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1265 - accuracy: 0.8382 - val_loss: 0.1577 - val_accuracy: 0.8000\n",
      "Epoch 714/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1267 - accuracy: 0.8382 - val_loss: 0.1584 - val_accuracy: 0.8000\n",
      "Epoch 715/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1264 - accuracy: 0.8382 - val_loss: 0.1577 - val_accuracy: 0.8000\n",
      "Epoch 716/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1264 - accuracy: 0.8382 - val_loss: 0.1569 - val_accuracy: 0.8000\n",
      "Epoch 717/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1266 - accuracy: 0.8439 - val_loss: 0.1564 - val_accuracy: 0.8000\n",
      "Epoch 718/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1263 - accuracy: 0.8439 - val_loss: 0.1576 - val_accuracy: 0.8000\n",
      "Epoch 719/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1258 - accuracy: 0.8439 - val_loss: 0.1586 - val_accuracy: 0.8000\n",
      "Epoch 720/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1255 - accuracy: 0.8497 - val_loss: 0.1584 - val_accuracy: 0.8000\n",
      "Epoch 721/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1256 - accuracy: 0.8439 - val_loss: 0.1593 - val_accuracy: 0.8000\n",
      "Epoch 722/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1254 - accuracy: 0.8382 - val_loss: 0.1591 - val_accuracy: 0.8000\n",
      "Epoch 723/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.8382 - val_loss: 0.1589 - val_accuracy: 0.8000\n",
      "Epoch 724/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1255 - accuracy: 0.8324 - val_loss: 0.1591 - val_accuracy: 0.8000\n",
      "Epoch 725/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1250 - accuracy: 0.8439 - val_loss: 0.1591 - val_accuracy: 0.8000\n",
      "Epoch 726/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1249 - accuracy: 0.8382 - val_loss: 0.1590 - val_accuracy: 0.8000\n",
      "Epoch 727/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1248 - accuracy: 0.8324 - val_loss: 0.1594 - val_accuracy: 0.8000\n",
      "Epoch 728/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1246 - accuracy: 0.8382 - val_loss: 0.1584 - val_accuracy: 0.8000\n",
      "Epoch 729/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.8382 - val_loss: 0.1591 - val_accuracy: 0.8000\n",
      "Epoch 730/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1243 - accuracy: 0.8439 - val_loss: 0.1597 - val_accuracy: 0.8000\n",
      "Epoch 731/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1246 - accuracy: 0.8439 - val_loss: 0.1592 - val_accuracy: 0.8000\n",
      "Epoch 732/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1243 - accuracy: 0.8439 - val_loss: 0.1613 - val_accuracy: 0.8000\n",
      "Epoch 733/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1243 - accuracy: 0.8382 - val_loss: 0.1620 - val_accuracy: 0.8000\n",
      "Epoch 734/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1238 - accuracy: 0.8497 - val_loss: 0.1597 - val_accuracy: 0.8000\n",
      "Epoch 735/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1245 - accuracy: 0.8497 - val_loss: 0.1576 - val_accuracy: 0.8000\n",
      "Epoch 736/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1240 - accuracy: 0.8497 - val_loss: 0.1592 - val_accuracy: 0.8000\n",
      "Epoch 737/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1235 - accuracy: 0.8497 - val_loss: 0.1594 - val_accuracy: 0.8000\n",
      "Epoch 738/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1236 - accuracy: 0.8497 - val_loss: 0.1588 - val_accuracy: 0.8000\n",
      "Epoch 739/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1233 - accuracy: 0.8439 - val_loss: 0.1594 - val_accuracy: 0.8000\n",
      "Epoch 740/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1232 - accuracy: 0.8439 - val_loss: 0.1583 - val_accuracy: 0.8000\n",
      "Epoch 741/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1230 - accuracy: 0.8439 - val_loss: 0.1575 - val_accuracy: 0.8000\n",
      "Epoch 742/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1236 - accuracy: 0.8439 - val_loss: 0.1584 - val_accuracy: 0.8000\n",
      "Epoch 743/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1226 - accuracy: 0.8439 - val_loss: 0.1557 - val_accuracy: 0.8000\n",
      "Epoch 744/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.8382 - val_loss: 0.1531 - val_accuracy: 0.8000\n",
      "Epoch 745/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1234 - accuracy: 0.8439 - val_loss: 0.1541 - val_accuracy: 0.8000\n",
      "Epoch 746/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1224 - accuracy: 0.8497 - val_loss: 0.1576 - val_accuracy: 0.8000\n",
      "Epoch 747/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1226 - accuracy: 0.8439 - val_loss: 0.1606 - val_accuracy: 0.8000\n",
      "Epoch 748/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1231 - accuracy: 0.8382 - val_loss: 0.1578 - val_accuracy: 0.8000\n",
      "Epoch 749/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.8497 - val_loss: 0.1561 - val_accuracy: 0.8000\n",
      "Epoch 750/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1221 - accuracy: 0.8497 - val_loss: 0.1553 - val_accuracy: 0.8000\n",
      "Epoch 751/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1222 - accuracy: 0.8497 - val_loss: 0.1569 - val_accuracy: 0.8000\n",
      "Epoch 752/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.8555 - val_loss: 0.1571 - val_accuracy: 0.8000\n",
      "Epoch 753/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1220 - accuracy: 0.8497 - val_loss: 0.1553 - val_accuracy: 0.8000\n",
      "Epoch 754/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1217 - accuracy: 0.8497 - val_loss: 0.1552 - val_accuracy: 0.8000\n",
      "Epoch 755/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1216 - accuracy: 0.8497 - val_loss: 0.1555 - val_accuracy: 0.8000\n",
      "Epoch 756/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.8497 - val_loss: 0.1544 - val_accuracy: 0.8000\n",
      "Epoch 757/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1213 - accuracy: 0.8497 - val_loss: 0.1536 - val_accuracy: 0.8000\n",
      "Epoch 758/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1214 - accuracy: 0.8382 - val_loss: 0.1524 - val_accuracy: 0.8000\n",
      "Epoch 759/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1211 - accuracy: 0.8382 - val_loss: 0.1534 - val_accuracy: 0.8000\n",
      "Epoch 760/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1210 - accuracy: 0.8439 - val_loss: 0.1541 - val_accuracy: 0.8000\n",
      "Epoch 761/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1208 - accuracy: 0.8555 - val_loss: 0.1550 - val_accuracy: 0.8000\n",
      "Epoch 762/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1209 - accuracy: 0.8555 - val_loss: 0.1566 - val_accuracy: 0.8000\n",
      "Epoch 763/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.8555 - val_loss: 0.1557 - val_accuracy: 0.8000\n",
      "Epoch 764/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1212 - accuracy: 0.8555 - val_loss: 0.1530 - val_accuracy: 0.8000\n",
      "Epoch 765/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1208 - accuracy: 0.8439 - val_loss: 0.1544 - val_accuracy: 0.8000\n",
      "Epoch 766/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1206 - accuracy: 0.8555 - val_loss: 0.1521 - val_accuracy: 0.8000\n",
      "Epoch 767/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1203 - accuracy: 0.8555 - val_loss: 0.1528 - val_accuracy: 0.8000\n",
      "Epoch 768/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1207 - accuracy: 0.8555 - val_loss: 0.1549 - val_accuracy: 0.8000\n",
      "Epoch 769/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1201 - accuracy: 0.8555 - val_loss: 0.1544 - val_accuracy: 0.8000\n",
      "Epoch 770/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1198 - accuracy: 0.8555 - val_loss: 0.1533 - val_accuracy: 0.8000\n",
      "Epoch 771/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.8555 - val_loss: 0.1522 - val_accuracy: 0.8000\n",
      "Epoch 772/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.8555 - val_loss: 0.1531 - val_accuracy: 0.8000\n",
      "Epoch 773/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1195 - accuracy: 0.8555 - val_loss: 0.1521 - val_accuracy: 0.8000\n",
      "Epoch 774/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1194 - accuracy: 0.8555 - val_loss: 0.1528 - val_accuracy: 0.8000\n",
      "Epoch 775/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1192 - accuracy: 0.8555 - val_loss: 0.1539 - val_accuracy: 0.8000\n",
      "Epoch 776/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1194 - accuracy: 0.8555 - val_loss: 0.1560 - val_accuracy: 0.8000\n",
      "Epoch 777/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.8613 - val_loss: 0.1557 - val_accuracy: 0.8000\n",
      "Epoch 778/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1190 - accuracy: 0.8497 - val_loss: 0.1524 - val_accuracy: 0.8000\n",
      "Epoch 779/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1192 - accuracy: 0.8497 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 780/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1192 - accuracy: 0.8439 - val_loss: 0.1525 - val_accuracy: 0.8000\n",
      "Epoch 781/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1188 - accuracy: 0.8613 - val_loss: 0.1543 - val_accuracy: 0.8000\n",
      "Epoch 782/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1191 - accuracy: 0.8555 - val_loss: 0.1558 - val_accuracy: 0.8000\n",
      "Epoch 783/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1189 - accuracy: 0.8555 - val_loss: 0.1550 - val_accuracy: 0.8000\n",
      "Epoch 784/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1185 - accuracy: 0.8497 - val_loss: 0.1534 - val_accuracy: 0.8000\n",
      "Epoch 785/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1181 - accuracy: 0.8555 - val_loss: 0.1537 - val_accuracy: 0.8000\n",
      "Epoch 786/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1182 - accuracy: 0.8613 - val_loss: 0.1532 - val_accuracy: 0.8000\n",
      "Epoch 787/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1180 - accuracy: 0.8613 - val_loss: 0.1535 - val_accuracy: 0.8000\n",
      "Epoch 788/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1180 - accuracy: 0.8613 - val_loss: 0.1532 - val_accuracy: 0.8000\n",
      "Epoch 789/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1179 - accuracy: 0.8555 - val_loss: 0.1520 - val_accuracy: 0.8000\n",
      "Epoch 790/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1178 - accuracy: 0.8555 - val_loss: 0.1526 - val_accuracy: 0.8000\n",
      "Epoch 791/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.8613 - val_loss: 0.1557 - val_accuracy: 0.8000\n",
      "Epoch 792/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1182 - accuracy: 0.8728 - val_loss: 0.1550 - val_accuracy: 0.8000\n",
      "Epoch 793/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.8613 - val_loss: 0.1515 - val_accuracy: 0.8000\n",
      "Epoch 794/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.8555 - val_loss: 0.1501 - val_accuracy: 0.8000\n",
      "Epoch 795/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1179 - accuracy: 0.8555 - val_loss: 0.1500 - val_accuracy: 0.8000\n",
      "Epoch 796/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.8439 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 797/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1173 - accuracy: 0.8497 - val_loss: 0.1517 - val_accuracy: 0.8000\n",
      "Epoch 798/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1170 - accuracy: 0.8497 - val_loss: 0.1512 - val_accuracy: 0.8000\n",
      "Epoch 799/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 0.8439 - val_loss: 0.1505 - val_accuracy: 0.8000\n",
      "Epoch 800/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1170 - accuracy: 0.8439 - val_loss: 0.1501 - val_accuracy: 0.8000\n",
      "Epoch 801/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1165 - accuracy: 0.8497 - val_loss: 0.1509 - val_accuracy: 0.8000\n",
      "Epoch 802/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1166 - accuracy: 0.8613 - val_loss: 0.1503 - val_accuracy: 0.8000\n",
      "Epoch 803/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1162 - accuracy: 0.8613 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 804/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1161 - accuracy: 0.8613 - val_loss: 0.1507 - val_accuracy: 0.8000\n",
      "Epoch 805/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1160 - accuracy: 0.8613 - val_loss: 0.1510 - val_accuracy: 0.8000\n",
      "Epoch 806/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1160 - accuracy: 0.8497 - val_loss: 0.1500 - val_accuracy: 0.8000\n",
      "Epoch 807/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1160 - accuracy: 0.8671 - val_loss: 0.1516 - val_accuracy: 0.8000\n",
      "Epoch 808/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.8728 - val_loss: 0.1512 - val_accuracy: 0.8000\n",
      "Epoch 809/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1156 - accuracy: 0.8728 - val_loss: 0.1511 - val_accuracy: 0.8000\n",
      "Epoch 810/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1155 - accuracy: 0.8671 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 811/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1153 - accuracy: 0.8555 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 812/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.8671 - val_loss: 0.1512 - val_accuracy: 0.8000\n",
      "Epoch 813/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1152 - accuracy: 0.8728 - val_loss: 0.1512 - val_accuracy: 0.8000\n",
      "Epoch 814/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1151 - accuracy: 0.8786 - val_loss: 0.1509 - val_accuracy: 0.8000\n",
      "Epoch 815/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1149 - accuracy: 0.8786 - val_loss: 0.1506 - val_accuracy: 0.8000\n",
      "Epoch 816/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1148 - accuracy: 0.8728 - val_loss: 0.1502 - val_accuracy: 0.8000\n",
      "Epoch 817/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1146 - accuracy: 0.8728 - val_loss: 0.1509 - val_accuracy: 0.8000\n",
      "Epoch 818/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1152 - accuracy: 0.8728 - val_loss: 0.1532 - val_accuracy: 0.8000\n",
      "Epoch 819/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1145 - accuracy: 0.8671 - val_loss: 0.1521 - val_accuracy: 0.8000\n",
      "Epoch 820/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1143 - accuracy: 0.8671 - val_loss: 0.1504 - val_accuracy: 0.8000\n",
      "Epoch 821/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.8671 - val_loss: 0.1486 - val_accuracy: 0.8000\n",
      "Epoch 822/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1141 - accuracy: 0.8728 - val_loss: 0.1474 - val_accuracy: 0.8000\n",
      "Epoch 823/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1142 - accuracy: 0.8728 - val_loss: 0.1480 - val_accuracy: 0.8000\n",
      "Epoch 824/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1143 - accuracy: 0.8671 - val_loss: 0.1482 - val_accuracy: 0.8000\n",
      "Epoch 825/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1136 - accuracy: 0.8728 - val_loss: 0.1493 - val_accuracy: 0.8000\n",
      "Epoch 826/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1136 - accuracy: 0.8671 - val_loss: 0.1508 - val_accuracy: 0.8000\n",
      "Epoch 827/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.8671 - val_loss: 0.1496 - val_accuracy: 0.8000\n",
      "Epoch 828/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1134 - accuracy: 0.8728 - val_loss: 0.1471 - val_accuracy: 0.8000\n",
      "Epoch 829/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1130 - accuracy: 0.8728 - val_loss: 0.1474 - val_accuracy: 0.8000\n",
      "Epoch 830/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1129 - accuracy: 0.8671 - val_loss: 0.1472 - val_accuracy: 0.8000\n",
      "Epoch 831/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1126 - accuracy: 0.8786 - val_loss: 0.1480 - val_accuracy: 0.8000\n",
      "Epoch 832/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.8728 - val_loss: 0.1470 - val_accuracy: 0.8000\n",
      "Epoch 833/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1125 - accuracy: 0.8786 - val_loss: 0.1457 - val_accuracy: 0.8500\n",
      "Epoch 834/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1124 - accuracy: 0.8728 - val_loss: 0.1452 - val_accuracy: 0.8000\n",
      "Epoch 835/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1122 - accuracy: 0.8728 - val_loss: 0.1461 - val_accuracy: 0.8000\n",
      "Epoch 836/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1123 - accuracy: 0.8786 - val_loss: 0.1475 - val_accuracy: 0.8500\n",
      "Epoch 837/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.8728 - val_loss: 0.1460 - val_accuracy: 0.8000\n",
      "Epoch 838/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.8613 - val_loss: 0.1463 - val_accuracy: 0.8000\n",
      "Epoch 839/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1116 - accuracy: 0.8786 - val_loss: 0.1473 - val_accuracy: 0.8000\n",
      "Epoch 840/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1115 - accuracy: 0.8671 - val_loss: 0.1478 - val_accuracy: 0.8000\n",
      "Epoch 841/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1114 - accuracy: 0.8671 - val_loss: 0.1472 - val_accuracy: 0.8000\n",
      "Epoch 842/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.8671 - val_loss: 0.1461 - val_accuracy: 0.8000\n",
      "Epoch 843/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1113 - accuracy: 0.8613 - val_loss: 0.1464 - val_accuracy: 0.8000\n",
      "Epoch 844/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1111 - accuracy: 0.8671 - val_loss: 0.1456 - val_accuracy: 0.8000\n",
      "Epoch 845/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1111 - accuracy: 0.8786 - val_loss: 0.1452 - val_accuracy: 0.8000\n",
      "Epoch 846/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1110 - accuracy: 0.8728 - val_loss: 0.1453 - val_accuracy: 0.8000\n",
      "Epoch 847/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.8786 - val_loss: 0.1454 - val_accuracy: 0.8000\n",
      "Epoch 848/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1106 - accuracy: 0.8728 - val_loss: 0.1466 - val_accuracy: 0.8500\n",
      "Epoch 849/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1108 - accuracy: 0.8728 - val_loss: 0.1477 - val_accuracy: 0.8500\n",
      "Epoch 850/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1106 - accuracy: 0.8728 - val_loss: 0.1456 - val_accuracy: 0.8500\n",
      "Epoch 851/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1104 - accuracy: 0.8844 - val_loss: 0.1458 - val_accuracy: 0.8000\n",
      "Epoch 852/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1103 - accuracy: 0.8728 - val_loss: 0.1458 - val_accuracy: 0.8000\n",
      "Epoch 853/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.8786 - val_loss: 0.1474 - val_accuracy: 0.8500\n",
      "Epoch 854/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1102 - accuracy: 0.8728 - val_loss: 0.1492 - val_accuracy: 0.8500\n",
      "Epoch 855/1000\n",
      "6/6 [==============================] - 0s 39ms/step - loss: 0.1101 - accuracy: 0.8728 - val_loss: 0.1486 - val_accuracy: 0.8000\n",
      "Epoch 856/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1102 - accuracy: 0.8728 - val_loss: 0.1493 - val_accuracy: 0.8500\n",
      "Epoch 857/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1103 - accuracy: 0.8786 - val_loss: 0.1471 - val_accuracy: 0.8000\n",
      "Epoch 858/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1098 - accuracy: 0.8786 - val_loss: 0.1482 - val_accuracy: 0.8000\n",
      "Epoch 859/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.8671 - val_loss: 0.1480 - val_accuracy: 0.8000\n",
      "Epoch 860/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1096 - accuracy: 0.8671 - val_loss: 0.1469 - val_accuracy: 0.8000\n",
      "Epoch 861/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1094 - accuracy: 0.8728 - val_loss: 0.1480 - val_accuracy: 0.8500\n",
      "Epoch 862/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.8728 - val_loss: 0.1492 - val_accuracy: 0.8500\n",
      "Epoch 863/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1094 - accuracy: 0.8728 - val_loss: 0.1472 - val_accuracy: 0.8000\n",
      "Epoch 864/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1090 - accuracy: 0.8786 - val_loss: 0.1472 - val_accuracy: 0.8000\n",
      "Epoch 865/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1091 - accuracy: 0.8844 - val_loss: 0.1469 - val_accuracy: 0.8000\n",
      "Epoch 866/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1092 - accuracy: 0.8786 - val_loss: 0.1470 - val_accuracy: 0.8000\n",
      "Epoch 867/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1097 - accuracy: 0.8671 - val_loss: 0.1485 - val_accuracy: 0.8500\n",
      "Epoch 868/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.8728 - val_loss: 0.1470 - val_accuracy: 0.8000\n",
      "Epoch 869/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.8786 - val_loss: 0.1452 - val_accuracy: 0.8000\n",
      "Epoch 870/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.8786 - val_loss: 0.1452 - val_accuracy: 0.8000\n",
      "Epoch 871/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.8786 - val_loss: 0.1451 - val_accuracy: 0.8000\n",
      "Epoch 872/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1087 - accuracy: 0.8786 - val_loss: 0.1458 - val_accuracy: 0.8500\n",
      "Epoch 873/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1086 - accuracy: 0.8786 - val_loss: 0.1469 - val_accuracy: 0.8500\n",
      "Epoch 874/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1083 - accuracy: 0.8728 - val_loss: 0.1453 - val_accuracy: 0.8500\n",
      "Epoch 875/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1084 - accuracy: 0.8786 - val_loss: 0.1431 - val_accuracy: 0.8000\n",
      "Epoch 876/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1080 - accuracy: 0.8728 - val_loss: 0.1434 - val_accuracy: 0.8500\n",
      "Epoch 877/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.8786 - val_loss: 0.1450 - val_accuracy: 0.8500\n",
      "Epoch 878/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1079 - accuracy: 0.8728 - val_loss: 0.1446 - val_accuracy: 0.8500\n",
      "Epoch 879/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.8844 - val_loss: 0.1435 - val_accuracy: 0.8500\n",
      "Epoch 880/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1077 - accuracy: 0.8728 - val_loss: 0.1427 - val_accuracy: 0.8500\n",
      "Epoch 881/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1076 - accuracy: 0.8786 - val_loss: 0.1433 - val_accuracy: 0.8500\n",
      "Epoch 882/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1074 - accuracy: 0.8844 - val_loss: 0.1441 - val_accuracy: 0.8500\n",
      "Epoch 883/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1075 - accuracy: 0.8786 - val_loss: 0.1468 - val_accuracy: 0.8500\n",
      "Epoch 884/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.8786 - val_loss: 0.1456 - val_accuracy: 0.8500\n",
      "Epoch 885/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1073 - accuracy: 0.8728 - val_loss: 0.1446 - val_accuracy: 0.8500\n",
      "Epoch 886/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.8786 - val_loss: 0.1457 - val_accuracy: 0.8500\n",
      "Epoch 887/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1065 - accuracy: 0.8786 - val_loss: 0.1477 - val_accuracy: 0.8500\n",
      "Epoch 888/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.8844 - val_loss: 0.1490 - val_accuracy: 0.8500\n",
      "Epoch 889/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.8844 - val_loss: 0.1462 - val_accuracy: 0.8500\n",
      "Epoch 890/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.8786 - val_loss: 0.1453 - val_accuracy: 0.8500\n",
      "Epoch 891/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.8786 - val_loss: 0.1428 - val_accuracy: 0.8500\n",
      "Epoch 892/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.8786 - val_loss: 0.1422 - val_accuracy: 0.8500\n",
      "Epoch 893/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1064 - accuracy: 0.8786 - val_loss: 0.1426 - val_accuracy: 0.8500\n",
      "Epoch 894/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.8844 - val_loss: 0.1439 - val_accuracy: 0.8500\n",
      "Epoch 895/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.8844 - val_loss: 0.1439 - val_accuracy: 0.8500\n",
      "Epoch 896/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1061 - accuracy: 0.8786 - val_loss: 0.1442 - val_accuracy: 0.8500\n",
      "Epoch 897/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1060 - accuracy: 0.8844 - val_loss: 0.1432 - val_accuracy: 0.8500\n",
      "Epoch 898/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1060 - accuracy: 0.8786 - val_loss: 0.1433 - val_accuracy: 0.8500\n",
      "Epoch 899/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.8844 - val_loss: 0.1448 - val_accuracy: 0.8500\n",
      "Epoch 900/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.8786 - val_loss: 0.1456 - val_accuracy: 0.8500\n",
      "Epoch 901/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1067 - accuracy: 0.8786 - val_loss: 0.1469 - val_accuracy: 0.8500\n",
      "Epoch 902/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1059 - accuracy: 0.8786 - val_loss: 0.1441 - val_accuracy: 0.8500\n",
      "Epoch 903/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1055 - accuracy: 0.8728 - val_loss: 0.1424 - val_accuracy: 0.8500\n",
      "Epoch 904/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.8786 - val_loss: 0.1419 - val_accuracy: 0.8500\n",
      "Epoch 905/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.8844 - val_loss: 0.1403 - val_accuracy: 0.8500\n",
      "Epoch 906/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1057 - accuracy: 0.8786 - val_loss: 0.1396 - val_accuracy: 0.8500\n",
      "Epoch 907/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.8728 - val_loss: 0.1407 - val_accuracy: 0.8500\n",
      "Epoch 908/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1057 - accuracy: 0.8728 - val_loss: 0.1440 - val_accuracy: 0.8500\n",
      "Epoch 909/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1050 - accuracy: 0.8844 - val_loss: 0.1431 - val_accuracy: 0.8500\n",
      "Epoch 910/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1046 - accuracy: 0.8786 - val_loss: 0.1426 - val_accuracy: 0.8500\n",
      "Epoch 911/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.8728 - val_loss: 0.1423 - val_accuracy: 0.8500\n",
      "Epoch 912/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1043 - accuracy: 0.8728 - val_loss: 0.1433 - val_accuracy: 0.8500\n",
      "Epoch 913/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1046 - accuracy: 0.8844 - val_loss: 0.1440 - val_accuracy: 0.8500\n",
      "Epoch 914/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 0.8844 - val_loss: 0.1420 - val_accuracy: 0.8500\n",
      "Epoch 915/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8728 - val_loss: 0.1416 - val_accuracy: 0.8500\n",
      "Epoch 916/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.8728 - val_loss: 0.1420 - val_accuracy: 0.8500\n",
      "Epoch 917/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1044 - accuracy: 0.8786 - val_loss: 0.1422 - val_accuracy: 0.8500\n",
      "Epoch 918/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1037 - accuracy: 0.8844 - val_loss: 0.1406 - val_accuracy: 0.8500\n",
      "Epoch 919/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.8786 - val_loss: 0.1403 - val_accuracy: 0.8500\n",
      "Epoch 920/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1039 - accuracy: 0.8728 - val_loss: 0.1415 - val_accuracy: 0.8500\n",
      "Epoch 921/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1038 - accuracy: 0.8786 - val_loss: 0.1422 - val_accuracy: 0.8500\n",
      "Epoch 922/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1039 - accuracy: 0.8786 - val_loss: 0.1414 - val_accuracy: 0.8500\n",
      "Epoch 923/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1036 - accuracy: 0.8786 - val_loss: 0.1404 - val_accuracy: 0.8500\n",
      "Epoch 924/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.8844 - val_loss: 0.1399 - val_accuracy: 0.8500\n",
      "Epoch 925/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1034 - accuracy: 0.8786 - val_loss: 0.1410 - val_accuracy: 0.8500\n",
      "Epoch 926/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1032 - accuracy: 0.8786 - val_loss: 0.1419 - val_accuracy: 0.8500\n",
      "Epoch 927/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1031 - accuracy: 0.8728 - val_loss: 0.1431 - val_accuracy: 0.8500\n",
      "Epoch 928/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.8844 - val_loss: 0.1441 - val_accuracy: 0.8500\n",
      "Epoch 929/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1033 - accuracy: 0.8786 - val_loss: 0.1433 - val_accuracy: 0.8500\n",
      "Epoch 930/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.8786 - val_loss: 0.1437 - val_accuracy: 0.8500\n",
      "Epoch 931/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1028 - accuracy: 0.8844 - val_loss: 0.1432 - val_accuracy: 0.8500\n",
      "Epoch 932/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1027 - accuracy: 0.8844 - val_loss: 0.1429 - val_accuracy: 0.8500\n",
      "Epoch 933/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1026 - accuracy: 0.8844 - val_loss: 0.1433 - val_accuracy: 0.8500\n",
      "Epoch 934/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1027 - accuracy: 0.8844 - val_loss: 0.1426 - val_accuracy: 0.8500\n",
      "Epoch 935/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1025 - accuracy: 0.8786 - val_loss: 0.1415 - val_accuracy: 0.8500\n",
      "Epoch 936/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.8786 - val_loss: 0.1408 - val_accuracy: 0.8500\n",
      "Epoch 937/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1023 - accuracy: 0.8786 - val_loss: 0.1405 - val_accuracy: 0.8500\n",
      "Epoch 938/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1022 - accuracy: 0.8728 - val_loss: 0.1411 - val_accuracy: 0.8500\n",
      "Epoch 939/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1026 - accuracy: 0.8728 - val_loss: 0.1420 - val_accuracy: 0.8500\n",
      "Epoch 940/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.8728 - val_loss: 0.1397 - val_accuracy: 0.8500\n",
      "Epoch 941/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1022 - accuracy: 0.8786 - val_loss: 0.1397 - val_accuracy: 0.8500\n",
      "Epoch 942/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.8786 - val_loss: 0.1402 - val_accuracy: 0.8500\n",
      "Epoch 943/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1022 - accuracy: 0.8786 - val_loss: 0.1414 - val_accuracy: 0.8500\n",
      "Epoch 944/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1016 - accuracy: 0.8902 - val_loss: 0.1405 - val_accuracy: 0.8500\n",
      "Epoch 945/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1015 - accuracy: 0.8902 - val_loss: 0.1391 - val_accuracy: 0.8500\n",
      "Epoch 946/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.8902 - val_loss: 0.1390 - val_accuracy: 0.8500\n",
      "Epoch 947/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1017 - accuracy: 0.8902 - val_loss: 0.1388 - val_accuracy: 0.8500\n",
      "Epoch 948/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.8902 - val_loss: 0.1417 - val_accuracy: 0.8500\n",
      "Epoch 949/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1019 - accuracy: 0.8844 - val_loss: 0.1403 - val_accuracy: 0.8500\n",
      "Epoch 950/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.8786 - val_loss: 0.1378 - val_accuracy: 0.8500\n",
      "Epoch 951/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.1011 - accuracy: 0.8844 - val_loss: 0.1379 - val_accuracy: 0.8500\n",
      "Epoch 952/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.8786 - val_loss: 0.1385 - val_accuracy: 0.8500\n",
      "Epoch 953/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1011 - accuracy: 0.8844 - val_loss: 0.1395 - val_accuracy: 0.8500\n",
      "Epoch 954/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1008 - accuracy: 0.8844 - val_loss: 0.1406 - val_accuracy: 0.8500\n",
      "Epoch 955/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1014 - accuracy: 0.8786 - val_loss: 0.1407 - val_accuracy: 0.8500\n",
      "Epoch 956/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.8844 - val_loss: 0.1388 - val_accuracy: 0.8500\n",
      "Epoch 957/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1009 - accuracy: 0.8844 - val_loss: 0.1383 - val_accuracy: 0.8500\n",
      "Epoch 958/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1007 - accuracy: 0.8844 - val_loss: 0.1384 - val_accuracy: 0.8500\n",
      "Epoch 959/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.8786 - val_loss: 0.1402 - val_accuracy: 0.8500\n",
      "Epoch 960/1000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1004 - accuracy: 0.8786 - val_loss: 0.1401 - val_accuracy: 0.8500\n",
      "Epoch 961/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1002 - accuracy: 0.8786 - val_loss: 0.1400 - val_accuracy: 0.8500\n",
      "Epoch 962/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.8786 - val_loss: 0.1386 - val_accuracy: 0.8500\n",
      "Epoch 963/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.8902 - val_loss: 0.1380 - val_accuracy: 0.8500\n",
      "Epoch 964/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.8844 - val_loss: 0.1391 - val_accuracy: 0.8500\n",
      "Epoch 965/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.8844 - val_loss: 0.1395 - val_accuracy: 0.8500\n",
      "Epoch 966/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.8844 - val_loss: 0.1393 - val_accuracy: 0.8500\n",
      "Epoch 967/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.8902 - val_loss: 0.1399 - val_accuracy: 0.8500\n",
      "Epoch 968/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.8902 - val_loss: 0.1389 - val_accuracy: 0.8500\n",
      "Epoch 969/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1000 - accuracy: 0.8902 - val_loss: 0.1376 - val_accuracy: 0.8500\n",
      "Epoch 970/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0997 - accuracy: 0.8902 - val_loss: 0.1389 - val_accuracy: 0.8500\n",
      "Epoch 971/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0994 - accuracy: 0.8844 - val_loss: 0.1389 - val_accuracy: 0.8500\n",
      "Epoch 972/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.8902 - val_loss: 0.1380 - val_accuracy: 0.8500\n",
      "Epoch 973/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.8844 - val_loss: 0.1385 - val_accuracy: 0.8500\n",
      "Epoch 974/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.8902 - val_loss: 0.1383 - val_accuracy: 0.8500\n",
      "Epoch 975/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0999 - accuracy: 0.8786 - val_loss: 0.1405 - val_accuracy: 0.8500\n",
      "Epoch 976/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.8786 - val_loss: 0.1387 - val_accuracy: 0.8500\n",
      "Epoch 977/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0989 - accuracy: 0.8844 - val_loss: 0.1383 - val_accuracy: 0.8500\n",
      "Epoch 978/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0990 - accuracy: 0.8902 - val_loss: 0.1377 - val_accuracy: 0.8500\n",
      "Epoch 979/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0990 - accuracy: 0.8902 - val_loss: 0.1379 - val_accuracy: 0.8500\n",
      "Epoch 980/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0989 - accuracy: 0.8844 - val_loss: 0.1396 - val_accuracy: 0.8500\n",
      "Epoch 981/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.8844 - val_loss: 0.1404 - val_accuracy: 0.8500\n",
      "Epoch 982/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.8902 - val_loss: 0.1386 - val_accuracy: 0.8500\n",
      "Epoch 983/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.8902 - val_loss: 0.1387 - val_accuracy: 0.8500\n",
      "Epoch 984/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0985 - accuracy: 0.8902 - val_loss: 0.1383 - val_accuracy: 0.8500\n",
      "Epoch 985/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0983 - accuracy: 0.8902 - val_loss: 0.1391 - val_accuracy: 0.8500\n",
      "Epoch 986/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.8844 - val_loss: 0.1410 - val_accuracy: 0.8500\n",
      "Epoch 987/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0985 - accuracy: 0.8786 - val_loss: 0.1408 - val_accuracy: 0.8500\n",
      "Epoch 988/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.8786 - val_loss: 0.1392 - val_accuracy: 0.8500\n",
      "Epoch 989/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0981 - accuracy: 0.8960 - val_loss: 0.1385 - val_accuracy: 0.8500\n",
      "Epoch 990/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0980 - accuracy: 0.8902 - val_loss: 0.1393 - val_accuracy: 0.8500\n",
      "Epoch 991/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.8902 - val_loss: 0.1388 - val_accuracy: 0.8500\n",
      "Epoch 992/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0977 - accuracy: 0.8844 - val_loss: 0.1392 - val_accuracy: 0.8500\n",
      "Epoch 993/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0978 - accuracy: 0.8786 - val_loss: 0.1395 - val_accuracy: 0.8500\n",
      "Epoch 994/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0975 - accuracy: 0.8844 - val_loss: 0.1385 - val_accuracy: 0.8500\n",
      "Epoch 995/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0979 - accuracy: 0.8902 - val_loss: 0.1381 - val_accuracy: 0.8500\n",
      "Epoch 996/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0975 - accuracy: 0.8902 - val_loss: 0.1385 - val_accuracy: 0.8500\n",
      "Epoch 997/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0974 - accuracy: 0.8902 - val_loss: 0.1376 - val_accuracy: 0.8500\n",
      "Epoch 998/1000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0973 - accuracy: 0.8902 - val_loss: 0.1377 - val_accuracy: 0.8500\n",
      "Epoch 999/1000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0970 - accuracy: 0.8902 - val_loss: 0.1383 - val_accuracy: 0.8500\n",
      "Epoch 1000/1000\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0979 - accuracy: 0.8844 - val_loss: 0.1396 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1437a2a90>"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "#model.fit(xTrain,yTrain, verbose=1, batch_size=5, epochs=10000)\n",
    "model.fit(xTrain, yTrain, epochs=1000, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset confusion matrix: \n",
      " [[ 5  3]\n",
      " [ 3 11]]\n",
      "Testing dataset Accuracy Score: \n",
      " 0.7272727272727273\n",
      "Testing dataset Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62         8\n",
      "           1       0.79      0.79      0.79        14\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.71      0.71      0.71        22\n",
      "weighted avg       0.73      0.73      0.73        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate the data set.\n",
    "predictTesting = model.predict_classes(xTest)\n",
    "\n",
    "\n",
    "print(\"Testing dataset confusion matrix: \\n\", confusion_matrix(yTest, predictTesting))\n",
    "print('Testing dataset Accuracy Score: \\n', accuracy_score(yTest, predictTesting))\n",
    "print('Testing dataset Report : \\n',classification_report(yTest, predictTesting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With KNN accuracy is:  0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "knn= KNeighborsClassifier()\n",
    "knn.fit(xTrain,yTrain)\n",
    "prediction = knn.predict(xTest)\n",
    "print('With KNN accuracy is: ',nb.score(xTest,yTest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Gaussian  accuracy is:  0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(xTrain,yTrain)\n",
    "prediction = nb.predict(xTest)\n",
    "print('With Gaussian  accuracy is: ',nb.score(xTest,yTest)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=12, kernel='poly')"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support vector machine\n",
    "clf = svm.SVC(kernel='poly',degree=12)\n",
    "clf.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [1]\n",
      "pred [0]\n",
      "pred [1]\n",
      "pred [0]\n",
      "pred [0]\n",
      "Testing dataset confusion matrix: \n",
      " [[ 2  6]\n",
      " [ 1 13]]\n",
      "Testing dataset Accuracy Score: \n",
      " 0.6818181818181818\n",
      "Testing dataset Report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.25      0.36         8\n",
      "           1       0.68      0.93      0.79        14\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.68      0.59      0.58        22\n",
      "weighted avg       0.68      0.68      0.63        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res=np.array([])\n",
    "for data in xTest:\n",
    "    pred = clf.predict([data])\n",
    "    pred=np.array(pred)\n",
    "    res = np.concatenate((res,pred))\n",
    "    print(\"pred\",pred)\n",
    "print(\"Testing dataset confusion matrix: \\n\", confusion_matrix(yTest, res))\n",
    "print('Testing dataset Accuracy Score: \\n', accuracy_score(yTest, res))\n",
    "print('Testing dataset Report : \\n',classification_report(yTest, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree [0.75       0.85       0.8        0.84210526 0.78947368 0.78947368\n",
      " 0.84210526 0.73684211 0.68421053 0.68421053]\n",
      "tree Accuracy: 0.78 (+/- 0.12)\n",
      "randomForest [0.75       0.95       0.95       0.89473684 0.84210526 0.89473684\n",
      " 1.         0.84210526 0.73684211 0.78947368]\n",
      "randomForest Accuracy: 0.86 (+/- 0.17)\n",
      "KNN [0.65       0.75       0.75       0.78947368 0.73684211 0.84210526\n",
      " 0.68421053 0.84210526 0.68421053 0.68421053]\n",
      "KNN Accuracy: 0.74 (+/- 0.13)\n",
      "Gaussian [0.75       0.9        0.85       0.73684211 0.78947368 0.89473684\n",
      " 0.94736842 0.89473684 0.78947368 0.78947368]\n",
      "Gaussian Accuracy: 0.83 (+/- 0.14)\n",
      "SVC [0.7        0.65       0.7        0.63157895 0.68421053 0.68421053\n",
      " 0.57894737 0.73684211 0.63157895 0.78947368]\n",
      "SVC Accuracy: 0.68 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "tree_scores = cross_val_score(tree, xTrain,yTrain, cv=10, scoring='accuracy')\n",
    "print(\"tree\",tree_scores)\n",
    "print(\"tree Accuracy: %0.2f (+/- %0.2f)\" % (tree_scores.mean(), tree_scores.std() * 2))\n",
    "\n",
    "forest_scores = cross_val_score(randomForest, xTrain,yTrain, cv=10, scoring='accuracy')\n",
    "print(\"randomForest\",forest_scores)\n",
    "print(\"randomForest Accuracy: %0.2f (+/- %0.2f)\" % (forest_scores.mean(), forest_scores.std() * 2))\n",
    "\n",
    "knn_scores = cross_val_score(knn, xTrain,yTrain, cv=10, scoring='accuracy')\n",
    "print(\"KNN\",knn_scores)\n",
    "print(\"KNN Accuracy: %0.2f (+/- %0.2f)\" % (knn_scores.mean(), knn_scores.std() * 2))\n",
    "\n",
    "\n",
    "nb_scores = cross_val_score(nb, xTrain,yTrain, cv=10, scoring='accuracy')\n",
    "print(\"Gaussian\",nb_scores)\n",
    "print(\"Gaussian Accuracy: %0.2f (+/- %0.2f)\" % (nb_scores.mean(), nb_scores.std() * 2))\n",
    "\n",
    "\n",
    "\n",
    "SVC_scores = cross_val_score(clf, xTrain,yTrain, cv=10, scoring='accuracy')\n",
    "print(\"SVC\",scores)\n",
    "print(\"SVC Accuracy: %0.2f (+/- %0.2f)\" % (SVC_scores.mean(), SVC_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for the plot\n",
    "methods = ['tree', 'randomForest', 'knn','gaussian','SVC']\n",
    "x_pos = np.arange(len(methods))\n",
    "mean = [tree_scores.mean(), forest_scores.mean(), knn_scores.mean(),nb_scores.mean(),SVC_scores.mean()]\n",
    "error = [tree_scores.std(),  forest_scores.std(), knn_scores.std(),nb_scores.std(),SVC_scores.std()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar(x_pos, mean, yerr=error, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "ax.set_ylabel('The cross validation scores')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(methods)\n",
    "ax.set_title('Cross Validation scores of different methods')\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "# Save the figure and show\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
